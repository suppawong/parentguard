{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.remove('Text classification.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [i for i in files if 'csv' in str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RandomForest_classification_report_sentence_representative_avg_alpha.csv',\n",
       " 'LightGBM_classification_report_word_feature_alpha.csv',\n",
       " 'SVM_classification_report_word_feature_alpha.csv',\n",
       " 'Imblearn_balancedCascade_classification_report_word_feature.csv',\n",
       " 'LightGBM_classification_report_sentence_representative_avg_alpha.csv',\n",
       " 'RandomForest_classification_report_word_feature_alpha.csv',\n",
       " 'RandomForest_classification_report_sentence_representative_avg.csv',\n",
       " 'LightGBM_classification_report_word_feature.csv',\n",
       " 'Imblearn_balancedBagging_classification_report_sentence_representative_avg.csv',\n",
       " 'Imblearn_balancedBagging_classification_report_word_feature_alpha.csv',\n",
       " 'Naive_bays_classification_report_sentence_representative_avg.csv',\n",
       " 'SVM_classification_report_sentence_representative_avg_alpha.csv',\n",
       " 'Naive_bays_classification_report_sentence_representative_avg_alpha.csv',\n",
       " 'Imblearn_balancedBagging_classification_report_word_feature.csv',\n",
       " 'Naive_bays_classification_report_word_feature.csv',\n",
       " 'Naive_bays_classification_report_word_feature_alpha.csv',\n",
       " 'Imblearn_balancedBagging_classification_report_sentence_representative_avg_alpha.csv',\n",
       " 'RandomForest_classification_report_word_feature.csv',\n",
       " 'LightGBM_classification_report_sentence_representative_avg.csv',\n",
       " 'SVM_classification_report_sentence_representative_avg.csv',\n",
       " 'SVM_classification_report_word_feature.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_type</th>\n",
       "      <th>alpha</th>\n",
       "      <th>threshold</th>\n",
       "      <th>type_class</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>support</th>\n",
       "      <th>auc_roc</th>\n",
       "      <th>auc_pr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test data ensemble(content context (threshold ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rude</td>\n",
       "      <td>0.625232</td>\n",
       "      <td>0.624535</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.768879</td>\n",
       "      <td>336</td>\n",
       "      <td>0.426973</td>\n",
       "      <td>0.546872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train data ensemble(content context (threshold...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rude</td>\n",
       "      <td>0.610673</td>\n",
       "      <td>0.605918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.754607</td>\n",
       "      <td>1290</td>\n",
       "      <td>0.280093</td>\n",
       "      <td>0.441589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test data ensemble(content context (threshold ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Rude</td>\n",
       "      <td>0.625232</td>\n",
       "      <td>0.626894</td>\n",
       "      <td>0.985119</td>\n",
       "      <td>0.766204</td>\n",
       "      <td>336</td>\n",
       "      <td>0.426973</td>\n",
       "      <td>0.546872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train data ensemble(content context (threshold...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Rude</td>\n",
       "      <td>0.632019</td>\n",
       "      <td>0.619299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764898</td>\n",
       "      <td>1290</td>\n",
       "      <td>0.280093</td>\n",
       "      <td>0.441589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test data ensemble(content context (threshold ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Rude</td>\n",
       "      <td>0.615955</td>\n",
       "      <td>0.627219</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.754448</td>\n",
       "      <td>336</td>\n",
       "      <td>0.426973</td>\n",
       "      <td>0.546872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           data_type  alpha  threshold  \\\n",
       "0  Test data ensemble(content context (threshold ...    0.0        0.0   \n",
       "1  Train data ensemble(content context (threshold...    0.0        0.0   \n",
       "2  Test data ensemble(content context (threshold ...    0.0        0.1   \n",
       "3  Train data ensemble(content context (threshold...    0.0        0.1   \n",
       "4  Test data ensemble(content context (threshold ...    0.0        0.2   \n",
       "\n",
       "  type_class  accuracy  precision    recall    fscore  support   auc_roc  \\\n",
       "0       Rude  0.625232   0.624535  1.000000  0.768879      336  0.426973   \n",
       "1       Rude  0.610673   0.605918  1.000000  0.754607     1290  0.280093   \n",
       "2       Rude  0.625232   0.626894  0.985119  0.766204      336  0.426973   \n",
       "3       Rude  0.632019   0.619299  1.000000  0.764898     1290  0.280093   \n",
       "4       Rude  0.615955   0.627219  0.946429  0.754448      336  0.426973   \n",
       "\n",
       "     auc_pr  \n",
       "0  0.546872  \n",
       "1  0.441589  \n",
       "2  0.546872  \n",
       "3  0.441589  \n",
       "4  0.546872  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Rude', 'Figurative', 'Offensive', 'Dirty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = dict()\n",
    "track = dict()\n",
    "track2 = dict()\n",
    "for i in classes:\n",
    "    score[i] = 0\n",
    "    track[i] = \"\"\n",
    "    track2[i] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['data_type', 'threshold', 'type_class', 'accuracy', 'precision',\n",
       "       'recall', 'fscore', 'support', 'auc_roc', 'auc_pr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in files:\n",
    "    df = pd.read_csv(j)\n",
    "    for k in df.iterrows():\n",
    "        if score[k[1]['type_class']] < k[1]['fscore'] and 'Test' in k[1]['data_type']:\n",
    "            score[k[1]['type_class']] = k[1]['fscore']\n",
    "            track[k[1]['type_class']] = f'{j}_{k[0]}'\n",
    "            track2[k[1]['type_class']] = str(k[1]['fscore']) + \", \" + str(k[1]['precision']) + \", \" + str(k[1]['recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rude': 0.9850746268656716,\n",
       " 'Figurative': 0.4571428571428572,\n",
       " 'Offensive': 0.2417582417582417,\n",
       " 'Dirty': 0.25}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rude': 'Imblearn_balancedBagging_classification_report_word_feature_alpha.csv_622',\n",
       " 'Figurative': 'RandomForest_classification_report_word_feature_alpha.csv_730',\n",
       " 'Offensive': 'RandomForest_classification_report_word_feature.csv_20',\n",
       " 'Dirty': 'Imblearn_balancedBagging_classification_report_word_feature_alpha.csv_960'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rude': '0.9850746268656716, 0.9880239520958084, 0.9821428571428572',\n",
       " 'Figurative': '0.4571428571428572, 0.41025641025641024, 0.5161290322580645',\n",
       " 'Offensive': '0.2417582417582417, 0.18333333333333326, 0.3548387096774194',\n",
       " 'Dirty': '0.25, 0.2, 0.3333333333333333'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
