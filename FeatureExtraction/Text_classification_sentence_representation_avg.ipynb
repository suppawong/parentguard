{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1404,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pythainlp\n",
    "from pythainlp import word_tokenize\n",
    "from pythainlp.corpus import wordnet\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import words\n",
    "import nltk\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "def split_word(text):\n",
    "            \n",
    "    \n",
    "    tokens = word_tokenize(text,engine='newmm')\n",
    "    \n",
    "  \n",
    "    \n",
    "    # หารากศัพท์ภาษาไทย และภาษาอังกฤษ\n",
    "    # English\n",
    "    tokens = [p_stemmer.stem(i) for i in tokens]\n",
    "    \n",
    "    # Thai\n",
    "    tokens_temp=[]\n",
    "    for i in tokens:\n",
    "        w_syn = wordnet.synsets(i)\n",
    "        if (len(w_syn)>0) and (len(w_syn[0].lemma_names('tha'))>0):\n",
    "            tokens_temp.append(w_syn[0].lemma_names('tha')[0])\n",
    "        else:\n",
    "            tokens_temp.append(i)\n",
    "    \n",
    "    tokens = tokens_temp\n",
    "    \n",
    "    # ลบตัวเลข\n",
    "    tokens = [i for i in tokens if not i.isnumeric()]\n",
    "    \n",
    "    # ลบช่องว่าง\n",
    "    tokens = [i for i in tokens if not ' ' in i]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import xlrd  \n",
    "import pandas as pd\n",
    "Corpus = pd.read_excel('corpus_comments_thai2fit.xlsx')\n",
    "#Corpus['comments'] = Corpus['comments'].astype('str')\n",
    "Corpus['reaction_num'] = Corpus['reaction_num'].astype('float')\n",
    "Corpus['reply_num'] = Corpus['reply_num'].astype('float')\n",
    "Corpus['reaction1'] = Corpus['reaction1'].astype('str')\n",
    "Corpus['reaction2'] = Corpus['reaction2'].astype('str')\n",
    "Corpus['reaction3'] = Corpus['reaction3'].astype('str')\n",
    "#Corpus['d_1'] = Corpus['d_1'].astype('float')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(Corpus[['d_0','d_1','d_2','d_3','d_4','d_5','d_6','d_7','d_8','d_9','d_10','d_11','d_12','d_13','d_14','d_15',\n",
    "                                                            'd_16','d_17','d_18','d_19','d_20','d_21','d_22','d_23','d_24','d_25','d_26','d_27','d_28','d_29','d_30','d_31','d_32','d_33','d_34','d_35','d_36','d_37','d_38','d_39','d_40','d_41','d_42','d_43','d_44','d_45','d_46','d_47','d_48','d_49','d_50','d_51','d_52','d_53','d_54','d_55','d_56','d_57','d_58','d_59','d_60','d_61','d_62','d_63','d_64','d_65','d_66','d_67','d_68','d_69','d_70','d_71','d_72','d_73','d_74','d_75','d_76','d_77','d_78','d_79','d_80','d_81','d_82','d_83','d_84','d_85','d_86','d_87','d_88','d_89','d_90','d_91','d_92','d_93','d_94','d_95','d_96','d_97','d_98','d_99',\n",
    "                                                            'reaction_num','reply_num','reaction1','reaction2','reaction3']], Corpus[['Rude','Figurative','Offensive','Dirty']], test_size=0.2,random_state=1000);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1405,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from  sklearn.metrics import precision_recall_fscore_support\n",
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "\n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='weighted'))\n",
    "\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support']\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list(metrics_summary),\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    \n",
    "#     total = support.sum() \n",
    "#     avg[-1] = total\n",
    "\n",
    "#     class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1406,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "def writeEvaluation(s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12,s13,s14,s15,s16):\n",
    "    f = open(\"classification_report_thai2fit.csv\", mode='a')\n",
    "    f.write(s1+\",\"+s2+\",\"+s3+\",\"+s4)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(s5+\",\"+s6+\",\"+s7+\",\"+s8)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(s9+\",\"+s10+\",\"+s11+\",\"+s12)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(s13+\",\"+s14+\",\"+s15+\",\"+s16)\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "def writeEvaluation_threshold_1_minus_threshold(s1,s2,s3,s4,s5,s6,s7,s8):\n",
    "    f = open(\"classification_report_thai2fit.csv\", mode='a')\n",
    "    f.write(s1+\",\"+s2+\",\"+s3+\",\"+s4)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(s5+\",\"+s6+\",\"+s7+\",\"+s8)\n",
    "    f.write(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "string='';\n",
    "def report_performance(predictions_class_train, predictions_class_test, predictions_class_train_c, predictions_class_test_c, type_class,threshold):\n",
    "    #Evaluation class (test data) \n",
    "    str1 = \"Test data (ensemble)\"\n",
    "    str2 = str(threshold)\n",
    "    str3 = str(type_class)\n",
    "    str4 = str(accuracy_score(predictions_class_test, Test_Y[type_class]))\n",
    "    print(type_class+\" Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature): \",\n",
    "          accuracy_score(predictions_class_test, Test_Y[type_class])*100)\n",
    "    print(\"Confusion Matrix: \\n\", confusion_matrix(Test_Y[type_class],predictions_class_test))\n",
    "    report = classification_report(Test_Y[type_class],predictions_class_test)\n",
    "    print(\"PRF: \\n\", report)\n",
    "    \n",
    "    print(\"-----------------------------------------------------------\\n\")\n",
    "    str5 = \"Test data (multiple features)\"\n",
    "    str6 = str(threshold)\n",
    "    str7 = str(type_class)\n",
    "    str8 = str(accuracy_score(predictions_class_test_c, Test_Y[type_class]))\n",
    "    print(type_class+\" Accuracy score(test data with multiple features):\", \n",
    "          accuracy_score(predictions_class_test_c, Test_Y[type_class])*100)\n",
    "    print(\"Confusion Matrix: \\n\", confusion_matrix(Test_Y[type_class],predictions_class_test_c))\n",
    "    report = classification_report(Test_Y[type_class],predictions_class_test_c);\n",
    "    print(\"PRF: \\n\", report)\n",
    "\n",
    "    print(\"-----------------------------------------------------------\\n\")\n",
    "\n",
    "    #Evaluation class (train data)\n",
    "    str9 = \"Train data (ensemble)\"\n",
    "    str10 = str(threshold)\n",
    "    str11 = str(type_class)\n",
    "    str12 = str(accuracy_score(predictions_class_train, Train_Y[type_class]))\n",
    "    print(type_class+\" Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature): \",\n",
    "          accuracy_score(predictions_class_train, Train_Y[type_class])*100)\n",
    "    print(\"Confusion Matrix: \\n\",confusion_matrix(Train_Y[type_class],predictions_class_train))\n",
    "    print(\"PRF: \\n\",classification_report(Train_Y[type_class],predictions_class_train))\n",
    "    print(\"-----------------------------------------------------------\\n\")\n",
    "    str13 = \"Train data (mulitple features)\"\n",
    "    str14 = str(threshold)\n",
    "    str15 = str(type_class)\n",
    "    str16 = str(accuracy_score(predictions_class_train_c, Train_Y[type_class]))\n",
    "    print(type_class+\" Accuracy score(train data with multiple features):\", \n",
    "          accuracy_score(predictions_class_train_c, Train_Y[type_class])*100)\n",
    "    print(\"Confusion Matrix: \\n\",confusion_matrix(Train_Y[type_class],predictions_class_train_c))\n",
    "    print(\"PRF: \\n\",classification_report(Train_Y[type_class],predictions_class_train_c))\n",
    "    print(\"___________________________________________________________________________________________________________\\n\")\n",
    "\n",
    "    writeEvaluation(str1,str2,str3,str4,str5,str6,str7,str8,str9,str10,str11,str12,str13,str14,str15,str16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1408,
   "metadata": {},
   "outputs": [],
   "source": [
    "string='';\n",
    "def report_performance_threshold_1_minus_threshold(predictions_class_train, predictions_class_test, type_class,threshold):\n",
    "     #Evaluation class (test data) \n",
    "    str1 = \"Test data ensemble(content context (threshold & 1-threshold))\"\n",
    "    str2 = str(threshold)\n",
    "    str3 = str(type_class)\n",
    "    str4 = str(accuracy_score(predictions_class_test, Test_Y[type_class]))\n",
    "    print(type_class+\" Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature): \",\n",
    "          accuracy_score(predictions_class_test, Test_Y[type_class])*100)\n",
    "    print(\"Confusion Matrix: \\n\", confusion_matrix(Test_Y[type_class],predictions_class_test))\n",
    "    report = classification_report(Test_Y[type_class],predictions_class_test)\n",
    "    print(\"PRF: \\n\", report)\n",
    "    print(\"-----------------------------------------------------------\\n\")\n",
    "    \n",
    "    #Evaluation class (train data)\n",
    "    str5 = \"Train data ensemble(content context (threshold & 1-threshold)\"\n",
    "    str6 = str(threshold)\n",
    "    str7 = str(type_class)\n",
    "    str8 = str(accuracy_score(predictions_class_train, Train_Y[type_class]))\n",
    "    print(type_class+\" Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature): \",\n",
    "          accuracy_score(predictions_class_train, Train_Y[type_class])*100)\n",
    "    print(\"Confusion Matrix: \\n\",confusion_matrix(Train_Y[type_class],predictions_class_train))\n",
    "    print(\"PRF: \\n\",classification_report(Train_Y[type_class],predictions_class_train))\n",
    "    print(\"___________________________________________________________________________________________________________\\n\")\n",
    "\n",
    "    writeEvaluation_threshold_1_minus_threshold(str1,str2,str3,str4,str5,str6,str7,str8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(list_predict_prob,threshold):\n",
    "    list_predict_class = [];\n",
    "    for i in range (len(list_predict_prob)):\n",
    "        if(list_predict_prob[i][1] > threshold):\n",
    "            list_predict_class.append(1)\n",
    "        else :\n",
    "            list_predict_class.append(0)\n",
    "    return list_predict_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeStrInReactionToNum(reaction_data=[]):\n",
    "    reaction = []\n",
    "    for i in reaction_data:\n",
    "        if(i == 'haha'):\n",
    "            reaction.append(1)\n",
    "        elif(i == 'like'):\n",
    "            reaction.append(2)\n",
    "        elif(i == 'angry'):\n",
    "            reaction.append(3)\n",
    "        elif(i == 'sad'):\n",
    "            reaction.append(4)\n",
    "        elif(i == 'wow'):\n",
    "            reaction.append(5)\n",
    "        elif(i == 'love'):\n",
    "            reaction.append(6)\n",
    "        else:\n",
    "            reaction.append(7)\n",
    "    return reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1411,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from statistics import mean \n",
    "#content feature\n",
    "train_content = [];\n",
    "test_content = [];\n",
    "for i in range(0,100):\n",
    "    #need to determine 10 decimals place because float 64 does not support large value\n",
    "    decimals = 10   \n",
    "    #minimum value of Train_X['d_'+str(i)] need to be added due to in fit function, input X must be non-negative\n",
    "    train_x_min = abs(round(Train_X['d_'+str(i)],decimals).min())\n",
    "    test_x_min = abs(round(Test_X['d_'+str(i)],decimals).min())\n",
    "    \n",
    "    Train_X['d_'+str(i)] = round(Train_X['d_'+str(i)],decimals)+train_x_min\n",
    "    Test_X['d_'+str(i)] = round(Test_X['d_'+str(i)],decimals)+test_x_min\n",
    "    #replace nan value with mean value of Train_X['d_'+str(i)]\n",
    "    Train_X['d_'+str(i)] = Train_X['d_'+str(i)].replace(np.nan, np.nanmean(Train_X['d_'+str(i)]))\n",
    "    Test_X['d_'+str(i)] = Test_X['d_'+str(i)].replace(np.nan, np.nanmean(Test_X['d_'+str(i)])) \n",
    "    train_content.append(csr_matrix(Train_X['d_'+str(i)].values.reshape(-1,1)))\n",
    "    test_content.append(csr_matrix(Test_X['d_'+str(i)].values.reshape(-1,1)))\n",
    "\n",
    "for w in range(0,100):\n",
    "    for j in train_content[w]:\n",
    "        if(j<0):\n",
    "            print(j)\n",
    "import numpy as np\n",
    "#context feature\n",
    "train_reaction_num = csr_matrix(Train_X['reaction_num'].values.reshape(-1, 1))\n",
    "test_reaction_num = csr_matrix(Test_X['reaction_num'].values.reshape(-1, 1))\n",
    "train_reply_num = csr_matrix(Train_X['reply_num'].values.reshape(-1,1))\n",
    "test_reply_num = csr_matrix(Test_X['reply_num'].values.reshape(-1,1))\n",
    "\n",
    "# Train_X['reaction1'] = np.nan_to_num(0)\n",
    "# Test_X['reaction1'] = np.nan_to_num(0)\n",
    "# Train_X['reaction2'] = np.nan_to_num(0)\n",
    "# Test_X['reaction2'] = np.nan_to_num(0)\n",
    "# Train_X['reaction3'] = np.nan_to_num(0)\n",
    "# Test_X['reaction3'] = np.nan_to_num(0)\n",
    "# train_reaction1_feat = csr_matrix(Train_X['reaction1'].values.reshape(-1,1))\n",
    "# test_reaction1_feat = csr_matrix(Test_X['reaction1'].values.reshape(-1, 1))\n",
    "# train_reaction2_feat = csr_matrix(Train_X['reaction2'].values.reshape(-1, 1))\n",
    "# test_reaction2_feat = csr_matrix(Test_X['reaction2'].values.reshape(-1, 1))\n",
    "# train_reaction3_feat = csr_matrix(Train_X['reaction3'].values.reshape(-1, 1))\n",
    "# test_reaction3_feat = csr_matrix(Test_X['reaction3'].values.reshape(-1, 1))\n",
    "\n",
    "train_reaction1 = changeStrInReactionToNum(Train_X['reaction1'])\n",
    "test_reaction1 = changeStrInReactionToNum(Test_X['reaction1'])\n",
    "train_reaction2 = changeStrInReactionToNum(Train_X['reaction2'])\n",
    "test_reaction2 =  changeStrInReactionToNum(Test_X['reaction2'])\n",
    "train_reaction3 = changeStrInReactionToNum(Train_X['reaction3'])\n",
    "test_reaction3=  changeStrInReactionToNum(Test_X['reaction3'])\n",
    "\n",
    "train_reaction1_feat = csr_matrix(train_reaction1).reshape(-1,1)\n",
    "test_reaction1_feat = csr_matrix(test_reaction1).reshape(-1,1)\n",
    "train_reaction2_feat = csr_matrix(train_reaction2).reshape(-1,1)\n",
    "test_reaction2_feat = csr_matrix(test_reaction2).reshape(-1,1)\n",
    "train_reaction3_feat = csr_matrix(train_reaction3).reshape(-1,1)\n",
    "test_reaction3_feat = csr_matrix(test_reaction3).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1412,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, csr_matrix\n",
    "train_feat = hstack([train_content[0],train_content[1],train_content[2],train_content[3],train_content[4],train_content[5],train_content[6],train_content[7],train_content[8],train_content[9],train_content[10],train_content[11],train_content[12],train_content[13],train_content[14],train_content[15],train_content[16],train_content[17],train_content[18],train_content[19],train_content[20],train_content[21],train_content[22],train_content[23],train_content[24],train_content[25],train_content[26],train_content[27],train_content[28],train_content[29],train_content[30],train_content[31],train_content[32],train_content[33],train_content[34],train_content[35],train_content[36],train_content[37],train_content[38],train_content[39],train_content[40],train_content[41],train_content[42],train_content[43],train_content[44],train_content[45],train_content[46],train_content[47],train_content[48],train_content[49],train_content[50],train_content[51],train_content[52],train_content[53],train_content[54],train_content[55],train_content[56],train_content[57],train_content[58],train_content[59],train_content[60],train_content[61],train_content[62],train_content[63],train_content[64],train_content[65],train_content[66],train_content[67],train_content[68],train_content[69],train_content[70],train_content[71],train_content[72],train_content[73],train_content[74],train_content[75],train_content[76],train_content[77],train_content[78],train_content[79],train_content[80],train_content[81],train_content[82],train_content[83],train_content[84],train_content[85],train_content[86],train_content[87],train_content[88],train_content[89],train_content[90],train_content[91],train_content[92],train_content[93],train_content[94],train_content[95],train_content[96],train_content[97],train_content[98],train_content[99], train_reaction_num, train_reply_num, train_reaction1_feat, train_reaction2_feat, train_reaction3_feat])\n",
    "test_feat = hstack([test_content[0],test_content[1],test_content[2],test_content[3],test_content[4],test_content[5],test_content[6],test_content[7],test_content[8],test_content[9],test_content[10],test_content[11],test_content[12],test_content[13],test_content[14],test_content[15],test_content[16],test_content[17],test_content[18],test_content[19],test_content[20],test_content[21],test_content[22],test_content[23],test_content[24],test_content[25],test_content[26],test_content[27],test_content[28],test_content[29],test_content[30],test_content[31],test_content[32],test_content[33],test_content[34],test_content[35],test_content[36],test_content[37],test_content[38],test_content[39],test_content[40],test_content[41],test_content[42],test_content[43],test_content[44],test_content[45],test_content[46],test_content[47],test_content[48],test_content[49],test_content[50],test_content[51],test_content[52],test_content[53],test_content[54],test_content[55],test_content[56],test_content[57],test_content[58],test_content[59],test_content[60],test_content[61],test_content[62],test_content[63],test_content[64],test_content[65],test_content[66],test_content[67],test_content[68],test_content[69],test_content[70],test_content[71],test_content[72],test_content[73],test_content[74],test_content[75],test_content[76],test_content[77],test_content[78],test_content[79],test_content[80],test_content[81],test_content[82],test_content[83],test_content[84],test_content[85],test_content[86],test_content[87],test_content[88],test_content[89],test_content[90],test_content[91],test_content[92],test_content[93],test_content[94],test_content[95],test_content[96],test_content[97],test_content[98],test_content[99],test_reaction_num, test_reply_num, test_reaction1_feat, test_reaction2_feat, test_reaction3_feat])\n",
    "train_feat_content = hstack([train_content[0],train_content[1],train_content[2],train_content[3],train_content[4],train_content[5],train_content[6],train_content[7],train_content[8],train_content[9],train_content[10],train_content[11],train_content[12],train_content[13],train_content[14],train_content[15],train_content[16],train_content[17],train_content[18],train_content[19],train_content[20],train_content[21],train_content[22],train_content[23],train_content[24],train_content[25],train_content[26],train_content[27],train_content[28],train_content[29],train_content[30],train_content[31],train_content[32],train_content[33],train_content[34],train_content[35],train_content[36],train_content[37],train_content[38],train_content[39],train_content[40],train_content[41],train_content[42],train_content[43],train_content[44],train_content[45],train_content[46],train_content[47],train_content[48],train_content[49],train_content[50],train_content[51],train_content[52],train_content[53],train_content[54],train_content[55],train_content[56],train_content[57],train_content[58],train_content[59],train_content[60],train_content[61],train_content[62],train_content[63],train_content[64],train_content[65],train_content[66],train_content[67],train_content[68],train_content[69],train_content[70],train_content[71],train_content[72],train_content[73],train_content[74],train_content[75],train_content[76],train_content[77],train_content[78],train_content[79],train_content[80],train_content[81],train_content[82],train_content[83],train_content[84],train_content[85],train_content[86],train_content[87],train_content[88],train_content[89],train_content[90],train_content[91],train_content[92],train_content[93],train_content[94],train_content[95],train_content[96],train_content[97],train_content[98],train_content[99]])\n",
    "test_feat_content = hstack([test_content[0],test_content[1],test_content[2],test_content[3],test_content[4],test_content[5],test_content[6],test_content[7],test_content[8],test_content[9],test_content[10],test_content[11],test_content[12],test_content[13],test_content[14],test_content[15],test_content[16],test_content[17],test_content[18],test_content[19],test_content[20],test_content[21],test_content[22],test_content[23],test_content[24],test_content[25],test_content[26],test_content[27],test_content[28],test_content[29],test_content[30],test_content[31],test_content[32],test_content[33],test_content[34],test_content[35],test_content[36],test_content[37],test_content[38],test_content[39],test_content[40],test_content[41],test_content[42],test_content[43],test_content[44],test_content[45],test_content[46],test_content[47],test_content[48],test_content[49],test_content[50],test_content[51],test_content[52],test_content[53],test_content[54],test_content[55],test_content[56],test_content[57],test_content[58],test_content[59],test_content[60],test_content[61],test_content[62],test_content[63],test_content[64],test_content[65],test_content[66],test_content[67],test_content[68],test_content[69],test_content[70],test_content[71],test_content[72],test_content[73],test_content[74],test_content[75],test_content[76],test_content[77],test_content[78],test_content[79],test_content[80],test_content[81],test_content[82],test_content[83],test_content[84],test_content[85],test_content[86],test_content[87],test_content[88],test_content[89],test_content[90],test_content[91],test_content[92],test_content[93],test_content[94],test_content[95],test_content[96],test_content[97],test_content[98],test_content[99]])\n",
    "train_feat_context = hstack([train_reaction_num, train_reply_num, train_reaction1_feat, train_reaction2_feat, train_reaction3_feat])\n",
    "test_feat_context = hstack([test_reaction_num, test_reply_num, test_reaction1_feat, test_reaction2_feat, test_reaction3_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  62.33766233766234\n",
      "Confusion Matrix: \n",
      " [[  0 203]\n",
      " [  0 336]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       203\n",
      "           1       0.62      1.00      0.77       336\n",
      "\n",
      "    accuracy                           0.62       539\n",
      "   macro avg       0.31      0.50      0.38       539\n",
      "weighted avg       0.39      0.62      0.48       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 63.26530612244898\n",
      "Confusion Matrix: \n",
      " [[ 29 174]\n",
      " [ 24 312]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.14      0.23       203\n",
      "           1       0.64      0.93      0.76       336\n",
      "\n",
      "    accuracy                           0.63       539\n",
      "   macro avg       0.59      0.54      0.49       539\n",
      "weighted avg       0.61      0.63      0.56       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  59.86078886310905\n",
      "Confusion Matrix: \n",
      " [[   0  865]\n",
      " [   0 1290]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       865\n",
      "           1       0.60      1.00      0.75      1290\n",
      "\n",
      "    accuracy                           0.60      2155\n",
      "   macro avg       0.30      0.50      0.37      2155\n",
      "weighted avg       0.36      0.60      0.45      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 59.58236658932715\n",
      "Confusion Matrix: \n",
      " [[  82  783]\n",
      " [  88 1202]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.09      0.16       865\n",
      "           1       0.61      0.93      0.73      1290\n",
      "\n",
      "    accuracy                           0.60      2155\n",
      "   macro avg       0.54      0.51      0.45      2155\n",
      "weighted avg       0.56      0.60      0.50      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  82.56029684601113\n",
      "Confusion Matrix: \n",
      " [[443  65]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90       508\n",
      "           1       0.03      0.06      0.04        31\n",
      "\n",
      "    accuracy                           0.83       539\n",
      "   macro avg       0.48      0.47      0.47       539\n",
      "weighted avg       0.89      0.83      0.85       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 82.74582560296847\n",
      "Confusion Matrix: \n",
      " [[444  64]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91       508\n",
      "           1       0.03      0.06      0.04        31\n",
      "\n",
      "    accuracy                           0.83       539\n",
      "   macro avg       0.48      0.47      0.47       539\n",
      "weighted avg       0.89      0.83      0.86       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  85.9860788863109\n",
      "Confusion Matrix: \n",
      " [[1830  222]\n",
      " [  80   23]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      2052\n",
      "           1       0.09      0.22      0.13       103\n",
      "\n",
      "    accuracy                           0.86      2155\n",
      "   macro avg       0.53      0.56      0.53      2155\n",
      "weighted avg       0.92      0.86      0.89      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 87.61020881670534\n",
      "Confusion Matrix: \n",
      " [[1867  185]\n",
      " [  82   21]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      2052\n",
      "           1       0.10      0.20      0.14       103\n",
      "\n",
      "    accuracy                           0.88      2155\n",
      "   macro avg       0.53      0.56      0.53      2155\n",
      "weighted avg       0.92      0.88      0.90      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  23.376623376623375\n",
      "Confusion Matrix: \n",
      " [[100 408]\n",
      " [  5  26]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.20      0.33       508\n",
      "           1       0.06      0.84      0.11        31\n",
      "\n",
      "    accuracy                           0.23       539\n",
      "   macro avg       0.51      0.52      0.22       539\n",
      "weighted avg       0.90      0.23      0.31       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 22.634508348794064\n",
      "Confusion Matrix: \n",
      " [[ 98 410]\n",
      " [  7  24]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.19      0.32       508\n",
      "           1       0.06      0.77      0.10        31\n",
      "\n",
      "    accuracy                           0.23       539\n",
      "   macro avg       0.49      0.48      0.21       539\n",
      "weighted avg       0.88      0.23      0.31       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  22.32018561484919\n",
      "Confusion Matrix: \n",
      " [[ 367 1653]\n",
      " [  21  114]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.18      0.30      2020\n",
      "           1       0.06      0.84      0.12       135\n",
      "\n",
      "    accuracy                           0.22      2155\n",
      "   macro avg       0.51      0.51      0.21      2155\n",
      "weighted avg       0.89      0.22      0.29      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 19.76798143851508\n",
      "Confusion Matrix: \n",
      " [[ 307 1713]\n",
      " [  16  119]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.15      0.26      2020\n",
      "           1       0.06      0.88      0.12       135\n",
      "\n",
      "    accuracy                           0.20      2155\n",
      "   macro avg       0.51      0.52      0.19      2155\n",
      "weighted avg       0.89      0.20      0.25      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  91.09461966604823\n",
      "Confusion Matrix: \n",
      " [[491  45]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       539\n",
      "   macro avg       0.50      0.46      0.48       539\n",
      "weighted avg       0.99      0.91      0.95       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 88.49721706864564\n",
      "Confusion Matrix: \n",
      " [[477  59]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88       539\n",
      "   macro avg       0.50      0.44      0.47       539\n",
      "weighted avg       0.99      0.88      0.93       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  91.1832946635731\n",
      "Confusion Matrix: \n",
      " [[1964  162]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.91      2155\n",
      "   macro avg       0.50      0.48      0.48      2155\n",
      "weighted avg       0.97      0.91      0.94      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 90.99767981438515\n",
      "Confusion Matrix: \n",
      " [[1958  168]\n",
      " [  26    3]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      2126\n",
      "           1       0.02      0.10      0.03        29\n",
      "\n",
      "    accuracy                           0.91      2155\n",
      "   macro avg       0.50      0.51      0.49      2155\n",
      "weighted avg       0.97      0.91      0.94      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  63.07977736549165\n",
      "Confusion Matrix: \n",
      " [[  5 198]\n",
      " [  1 335]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.02      0.05       203\n",
      "           1       0.63      1.00      0.77       336\n",
      "\n",
      "    accuracy                           0.63       539\n",
      "   macro avg       0.73      0.51      0.41       539\n",
      "weighted avg       0.71      0.63      0.50       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 62.708719851577\n",
      "Confusion Matrix: \n",
      " [[ 31 172]\n",
      " [ 29 307]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.15      0.24       203\n",
      "           1       0.64      0.91      0.75       336\n",
      "\n",
      "    accuracy                           0.63       539\n",
      "   macro avg       0.58      0.53      0.49       539\n",
      "weighted avg       0.59      0.63      0.56       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  60.417633410672856\n",
      "Confusion Matrix: \n",
      " [[  12  853]\n",
      " [   0 1290]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.03       865\n",
      "           1       0.60      1.00      0.75      1290\n",
      "\n",
      "    accuracy                           0.60      2155\n",
      "   macro avg       0.80      0.51      0.39      2155\n",
      "weighted avg       0.76      0.60      0.46      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 59.39675174013921\n",
      "Confusion Matrix: \n",
      " [[  95  770]\n",
      " [ 105 1185]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.11      0.18       865\n",
      "           1       0.61      0.92      0.73      1290\n",
      "\n",
      "    accuracy                           0.59      2155\n",
      "   macro avg       0.54      0.51      0.45      2155\n",
      "weighted avg       0.55      0.59      0.51      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  84.60111317254174\n",
      "Confusion Matrix: \n",
      " [[454  54]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92       508\n",
      "           1       0.04      0.06      0.05        31\n",
      "\n",
      "    accuracy                           0.85       539\n",
      "   macro avg       0.49      0.48      0.48       539\n",
      "weighted avg       0.89      0.85      0.87       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 83.30241187384044\n",
      "Confusion Matrix: \n",
      " [[447  61]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91       508\n",
      "           1       0.03      0.06      0.04        31\n",
      "\n",
      "    accuracy                           0.83       539\n",
      "   macro avg       0.49      0.47      0.48       539\n",
      "weighted avg       0.89      0.83      0.86       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  87.19257540603247\n",
      "Confusion Matrix: \n",
      " [[1859  193]\n",
      " [  83   20]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      2052\n",
      "           1       0.09      0.19      0.13       103\n",
      "\n",
      "    accuracy                           0.87      2155\n",
      "   macro avg       0.53      0.55      0.53      2155\n",
      "weighted avg       0.92      0.87      0.89      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 87.70301624129931\n",
      "Confusion Matrix: \n",
      " [[1872  180]\n",
      " [  85   18]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      2052\n",
      "           1       0.09      0.17      0.12       103\n",
      "\n",
      "    accuracy                           0.88      2155\n",
      "   macro avg       0.52      0.54      0.53      2155\n",
      "weighted avg       0.92      0.88      0.89      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  26.34508348794063\n",
      "Confusion Matrix: \n",
      " [[118 390]\n",
      " [  7  24]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.23      0.37       508\n",
      "           1       0.06      0.77      0.11        31\n",
      "\n",
      "    accuracy                           0.26       539\n",
      "   macro avg       0.50      0.50      0.24       539\n",
      "weighted avg       0.89      0.26      0.36       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 24.675324675324674\n",
      "Confusion Matrix: \n",
      " [[109 399]\n",
      " [  7  24]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.21      0.35       508\n",
      "           1       0.06      0.77      0.11        31\n",
      "\n",
      "    accuracy                           0.25       539\n",
      "   macro avg       0.50      0.49      0.23       539\n",
      "weighted avg       0.89      0.25      0.34       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  26.07888631090487\n",
      "Confusion Matrix: \n",
      " [[ 451 1569]\n",
      " [  24  111]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.22      0.36      2020\n",
      "           1       0.07      0.82      0.12       135\n",
      "\n",
      "    accuracy                           0.26      2155\n",
      "   macro avg       0.51      0.52      0.24      2155\n",
      "weighted avg       0.89      0.26      0.35      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 20.649651972157773\n",
      "Confusion Matrix: \n",
      " [[ 328 1692]\n",
      " [  18  117]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.16      0.28      2020\n",
      "           1       0.06      0.87      0.12       135\n",
      "\n",
      "    accuracy                           0.21      2155\n",
      "   macro avg       0.51      0.51      0.20      2155\n",
      "weighted avg       0.89      0.21      0.27      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  91.4656771799629\n",
      "Confusion Matrix: \n",
      " [[493  43]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       539\n",
      "   macro avg       0.50      0.46      0.48       539\n",
      "weighted avg       0.99      0.91      0.95       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 89.42486085343229\n",
      "Confusion Matrix: \n",
      " [[482  54]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.89       539\n",
      "   macro avg       0.50      0.45      0.47       539\n",
      "weighted avg       0.99      0.89      0.94       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  92.01856148491879\n",
      "Confusion Matrix: \n",
      " [[1982  144]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.92      2155\n",
      "   macro avg       0.50      0.48      0.48      2155\n",
      "weighted avg       0.97      0.92      0.95      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 91.32250580046404\n",
      "Confusion Matrix: \n",
      " [[1966  160]\n",
      " [  27    2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      2126\n",
      "           1       0.01      0.07      0.02        29\n",
      "\n",
      "    accuracy                           0.91      2155\n",
      "   macro avg       0.50      0.50      0.49      2155\n",
      "weighted avg       0.97      0.91      0.94      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  64.56400742115028\n",
      "Confusion Matrix: \n",
      " [[ 26 177]\n",
      " [ 14 322]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.13      0.21       203\n",
      "           1       0.65      0.96      0.77       336\n",
      "\n",
      "    accuracy                           0.65       539\n",
      "   macro avg       0.65      0.54      0.49       539\n",
      "weighted avg       0.65      0.65      0.56       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 62.708719851577\n",
      "Confusion Matrix: \n",
      " [[ 36 167]\n",
      " [ 34 302]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.18      0.26       203\n",
      "           1       0.64      0.90      0.75       336\n",
      "\n",
      "    accuracy                           0.63       539\n",
      "   macro avg       0.58      0.54      0.51       539\n",
      "weighted avg       0.60      0.63      0.57       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  60.8816705336427\n",
      "Confusion Matrix: \n",
      " [[  66  799]\n",
      " [  44 1246]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.08      0.14       865\n",
      "           1       0.61      0.97      0.75      1290\n",
      "\n",
      "    accuracy                           0.61      2155\n",
      "   macro avg       0.60      0.52      0.44      2155\n",
      "weighted avg       0.61      0.61      0.50      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 59.53596287703016\n",
      "Confusion Matrix: \n",
      " [[ 109  756]\n",
      " [ 116 1174]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.13      0.20       865\n",
      "           1       0.61      0.91      0.73      1290\n",
      "\n",
      "    accuracy                           0.60      2155\n",
      "   macro avg       0.55      0.52      0.46      2155\n",
      "weighted avg       0.56      0.60      0.52      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  84.97217068645641\n",
      "Confusion Matrix: \n",
      " [[456  52]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       508\n",
      "           1       0.04      0.06      0.05        31\n",
      "\n",
      "    accuracy                           0.85       539\n",
      "   macro avg       0.49      0.48      0.48       539\n",
      "weighted avg       0.89      0.85      0.87       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 83.48794063079778\n",
      "Confusion Matrix: \n",
      " [[448  60]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91       508\n",
      "           1       0.03      0.06      0.04        31\n",
      "\n",
      "    accuracy                           0.83       539\n",
      "   macro avg       0.49      0.47      0.48       539\n",
      "weighted avg       0.89      0.83      0.86       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  87.61020881670534\n",
      "Confusion Matrix: \n",
      " [[1870  182]\n",
      " [  85   18]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      2052\n",
      "           1       0.09      0.17      0.12       103\n",
      "\n",
      "    accuracy                           0.88      2155\n",
      "   macro avg       0.52      0.54      0.53      2155\n",
      "weighted avg       0.92      0.88      0.89      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 87.70301624129931\n",
      "Confusion Matrix: \n",
      " [[1874  178]\n",
      " [  87   16]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      2052\n",
      "           1       0.08      0.16      0.11       103\n",
      "\n",
      "    accuracy                           0.88      2155\n",
      "   macro avg       0.52      0.53      0.52      2155\n",
      "weighted avg       0.91      0.88      0.89      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  29.313543599257883\n",
      "Confusion Matrix: \n",
      " [[137 371]\n",
      " [ 10  21]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.27      0.42       508\n",
      "           1       0.05      0.68      0.10        31\n",
      "\n",
      "    accuracy                           0.29       539\n",
      "   macro avg       0.49      0.47      0.26       539\n",
      "weighted avg       0.88      0.29      0.40       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 25.60296846011132\n",
      "Confusion Matrix: \n",
      " [[115 393]\n",
      " [  8  23]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.23      0.36       508\n",
      "           1       0.06      0.74      0.10        31\n",
      "\n",
      "    accuracy                           0.26       539\n",
      "   macro avg       0.50      0.48      0.23       539\n",
      "weighted avg       0.88      0.26      0.35       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  30.069605568445475\n",
      "Confusion Matrix: \n",
      " [[ 541 1479]\n",
      " [  28  107]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.27      0.42      2020\n",
      "           1       0.07      0.79      0.12       135\n",
      "\n",
      "    accuracy                           0.30      2155\n",
      "   macro avg       0.51      0.53      0.27      2155\n",
      "weighted avg       0.90      0.30      0.40      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 21.392111368909514\n",
      "Confusion Matrix: \n",
      " [[ 345 1675]\n",
      " [  19  116]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.17      0.29      2020\n",
      "           1       0.06      0.86      0.12       135\n",
      "\n",
      "    accuracy                           0.21      2155\n",
      "   macro avg       0.51      0.52      0.20      2155\n",
      "weighted avg       0.89      0.21      0.28      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  91.4656771799629\n",
      "Confusion Matrix: \n",
      " [[493  43]\n",
      " [  3   0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       539\n",
      "   macro avg       0.50      0.46      0.48       539\n",
      "weighted avg       0.99      0.91      0.95       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 89.6103896103896\n",
      "Confusion Matrix: \n",
      " [[483  53]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.95       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.90       539\n",
      "   macro avg       0.50      0.45      0.47       539\n",
      "weighted avg       0.99      0.90      0.94       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  92.52900232018561\n",
      "Confusion Matrix: \n",
      " [[1993  133]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.93      2155\n",
      "   macro avg       0.50      0.49      0.49      2155\n",
      "weighted avg       0.97      0.93      0.95      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 91.46171693735499\n",
      "Confusion Matrix: \n",
      " [[1969  157]\n",
      " [  27    2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      2126\n",
      "           1       0.01      0.07      0.02        29\n",
      "\n",
      "    accuracy                           0.91      2155\n",
      "   macro avg       0.50      0.50      0.49      2155\n",
      "weighted avg       0.97      0.91      0.94      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  63.07977736549165\n",
      "Confusion Matrix: \n",
      " [[ 32 171]\n",
      " [ 28 308]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.16      0.24       203\n",
      "           1       0.64      0.92      0.76       336\n",
      "\n",
      "    accuracy                           0.63       539\n",
      "   macro avg       0.59      0.54      0.50       539\n",
      "weighted avg       0.60      0.63      0.56       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 63.07977736549165\n",
      "Confusion Matrix: \n",
      " [[ 41 162]\n",
      " [ 37 299]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.20      0.29       203\n",
      "           1       0.65      0.89      0.75       336\n",
      "\n",
      "    accuracy                           0.63       539\n",
      "   macro avg       0.59      0.55      0.52       539\n",
      "weighted avg       0.60      0.63      0.58       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  59.953596287703014\n",
      "Confusion Matrix: \n",
      " [[ 102  763]\n",
      " [ 100 1190]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.12      0.19       865\n",
      "           1       0.61      0.92      0.73      1290\n",
      "\n",
      "    accuracy                           0.60      2155\n",
      "   macro avg       0.56      0.52      0.46      2155\n",
      "weighted avg       0.57      0.60      0.52      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 59.39675174013921\n",
      "Confusion Matrix: \n",
      " [[ 123  742]\n",
      " [ 133 1157]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.14      0.22       865\n",
      "           1       0.61      0.90      0.73      1290\n",
      "\n",
      "    accuracy                           0.59      2155\n",
      "   macro avg       0.54      0.52      0.47      2155\n",
      "weighted avg       0.56      0.59      0.52      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  85.34322820037106\n",
      "Confusion Matrix: \n",
      " [[458  50]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       508\n",
      "           1       0.04      0.06      0.05        31\n",
      "\n",
      "    accuracy                           0.85       539\n",
      "   macro avg       0.49      0.48      0.48       539\n",
      "weighted avg       0.89      0.85      0.87       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 83.48794063079778\n",
      "Confusion Matrix: \n",
      " [[448  60]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91       508\n",
      "           1       0.03      0.06      0.04        31\n",
      "\n",
      "    accuracy                           0.83       539\n",
      "   macro avg       0.49      0.47      0.48       539\n",
      "weighted avg       0.89      0.83      0.86       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  88.12064965197216\n",
      "Confusion Matrix: \n",
      " [[1883  169]\n",
      " [  87   16]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      2052\n",
      "           1       0.09      0.16      0.11       103\n",
      "\n",
      "    accuracy                           0.88      2155\n",
      "   macro avg       0.52      0.54      0.52      2155\n",
      "weighted avg       0.91      0.88      0.90      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 87.93503480278422\n",
      "Confusion Matrix: \n",
      " [[1879  173]\n",
      " [  87   16]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      2052\n",
      "           1       0.08      0.16      0.11       103\n",
      "\n",
      "    accuracy                           0.88      2155\n",
      "   macro avg       0.52      0.54      0.52      2155\n",
      "weighted avg       0.91      0.88      0.90      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  39.332096474953616\n",
      "Confusion Matrix: \n",
      " [[191 317]\n",
      " [ 10  21]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.38      0.54       508\n",
      "           1       0.06      0.68      0.11        31\n",
      "\n",
      "    accuracy                           0.39       539\n",
      "   macro avg       0.51      0.53      0.33       539\n",
      "weighted avg       0.90      0.39      0.51       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 26.53061224489796\n",
      "Confusion Matrix: \n",
      " [[120 388]\n",
      " [  8  23]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.24      0.38       508\n",
      "           1       0.06      0.74      0.10        31\n",
      "\n",
      "    accuracy                           0.27       539\n",
      "   macro avg       0.50      0.49      0.24       539\n",
      "weighted avg       0.89      0.27      0.36       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  40.696055684454755\n",
      "Confusion Matrix: \n",
      " [[ 778 1242]\n",
      " [  36   99]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.39      0.55      2020\n",
      "           1       0.07      0.73      0.13       135\n",
      "\n",
      "    accuracy                           0.41      2155\n",
      "   macro avg       0.51      0.56      0.34      2155\n",
      "weighted avg       0.90      0.41      0.52      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 22.32018561484919\n",
      "Confusion Matrix: \n",
      " [[ 365 1655]\n",
      " [  19  116]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.18      0.30      2020\n",
      "           1       0.07      0.86      0.12       135\n",
      "\n",
      "    accuracy                           0.22      2155\n",
      "   macro avg       0.51      0.52      0.21      2155\n",
      "weighted avg       0.90      0.22      0.29      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  91.83673469387756\n",
      "Confusion Matrix: \n",
      " [[495  41]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.92       539\n",
      "   macro avg       0.50      0.46      0.48       539\n",
      "weighted avg       0.99      0.92      0.95       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 89.98144712430427\n",
      "Confusion Matrix: \n",
      " [[485  51]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.95       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.90       539\n",
      "   macro avg       0.50      0.45      0.47       539\n",
      "weighted avg       0.99      0.90      0.94       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  92.80742459396751\n",
      "Confusion Matrix: \n",
      " [[1999  127]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.93      2155\n",
      "   macro avg       0.50      0.49      0.49      2155\n",
      "weighted avg       0.97      0.93      0.95      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 91.50812064965197\n",
      "Confusion Matrix: \n",
      " [[1971  155]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.92      2155\n",
      "   macro avg       0.50      0.48      0.48      2155\n",
      "weighted avg       0.97      0.92      0.94      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  63.07977736549165\n",
      "Confusion Matrix: \n",
      " [[ 41 162]\n",
      " [ 37 299]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.20      0.29       203\n",
      "           1       0.65      0.89      0.75       336\n",
      "\n",
      "    accuracy                           0.63       539\n",
      "   macro avg       0.59      0.55      0.52       539\n",
      "weighted avg       0.60      0.63      0.58       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 63.821892393320965\n",
      "Confusion Matrix: \n",
      " [[ 48 155]\n",
      " [ 40 296]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.24      0.33       203\n",
      "           1       0.66      0.88      0.75       336\n",
      "\n",
      "    accuracy                           0.64       539\n",
      "   macro avg       0.60      0.56      0.54       539\n",
      "weighted avg       0.61      0.64      0.59       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  59.86078886310905\n",
      "Confusion Matrix: \n",
      " [[ 134  731]\n",
      " [ 134 1156]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.15      0.24       865\n",
      "           1       0.61      0.90      0.73      1290\n",
      "\n",
      "    accuracy                           0.60      2155\n",
      "   macro avg       0.56      0.53      0.48      2155\n",
      "weighted avg       0.57      0.60      0.53      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 59.675174013921115\n",
      "Confusion Matrix: \n",
      " [[ 139  726]\n",
      " [ 143 1147]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.16      0.24       865\n",
      "           1       0.61      0.89      0.73      1290\n",
      "\n",
      "    accuracy                           0.60      2155\n",
      "   macro avg       0.55      0.52      0.48      2155\n",
      "weighted avg       0.56      0.60      0.53      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  86.08534322820037\n",
      "Confusion Matrix: \n",
      " [[462  46]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92       508\n",
      "           1       0.04      0.06      0.05        31\n",
      "\n",
      "    accuracy                           0.86       539\n",
      "   macro avg       0.49      0.49      0.49       539\n",
      "weighted avg       0.89      0.86      0.87       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 83.85899814471243\n",
      "Confusion Matrix: \n",
      " [[450  58]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       508\n",
      "           1       0.03      0.06      0.04        31\n",
      "\n",
      "    accuracy                           0.84       539\n",
      "   macro avg       0.49      0.48      0.48       539\n",
      "weighted avg       0.89      0.84      0.86       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  88.90951276102088\n",
      "Confusion Matrix: \n",
      " [[1903  149]\n",
      " [  90   13]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      2052\n",
      "           1       0.08      0.13      0.10       103\n",
      "\n",
      "    accuracy                           0.89      2155\n",
      "   macro avg       0.52      0.53      0.52      2155\n",
      "weighted avg       0.91      0.89      0.90      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 88.21345707656613\n",
      "Confusion Matrix: \n",
      " [[1885  167]\n",
      " [  87   16]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      2052\n",
      "           1       0.09      0.16      0.11       103\n",
      "\n",
      "    accuracy                           0.88      2155\n",
      "   macro avg       0.52      0.54      0.52      2155\n",
      "weighted avg       0.91      0.88      0.90      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  57.69944341372912\n",
      "Confusion Matrix: \n",
      " [[293 215]\n",
      " [ 13  18]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.58      0.72       508\n",
      "           1       0.08      0.58      0.14        31\n",
      "\n",
      "    accuracy                           0.58       539\n",
      "   macro avg       0.52      0.58      0.43       539\n",
      "weighted avg       0.91      0.58      0.69       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 28.942486085343226\n",
      "Confusion Matrix: \n",
      " [[135 373]\n",
      " [ 10  21]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.27      0.41       508\n",
      "           1       0.05      0.68      0.10        31\n",
      "\n",
      "    accuracy                           0.29       539\n",
      "   macro avg       0.49      0.47      0.26       539\n",
      "weighted avg       0.88      0.29      0.40       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  52.43619489559165\n",
      "Confusion Matrix: \n",
      " [[1042  978]\n",
      " [  47   88]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.52      0.67      2020\n",
      "           1       0.08      0.65      0.15       135\n",
      "\n",
      "    accuracy                           0.52      2155\n",
      "   macro avg       0.52      0.58      0.41      2155\n",
      "weighted avg       0.90      0.52      0.64      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 23.48027842227378\n",
      "Confusion Matrix: \n",
      " [[ 391 1629]\n",
      " [  20  115]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.19      0.32      2020\n",
      "           1       0.07      0.85      0.12       135\n",
      "\n",
      "    accuracy                           0.23      2155\n",
      "   macro avg       0.51      0.52      0.22      2155\n",
      "weighted avg       0.90      0.23      0.31      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.06307977736549\n",
      "Confusion Matrix: \n",
      " [[507  29]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.50      0.47      0.48       539\n",
      "weighted avg       0.99      0.94      0.96       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 90.16697588126159\n",
      "Confusion Matrix: \n",
      " [[486  50]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.90       539\n",
      "   macro avg       0.50      0.45      0.47       539\n",
      "weighted avg       0.99      0.90      0.94       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  94.06032482598607\n",
      "Confusion Matrix: \n",
      " [[2026  100]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      2126\n",
      "           1       0.01      0.03      0.02        29\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.50      0.49      0.49      2155\n",
      "weighted avg       0.97      0.94      0.96      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 91.69373549883991\n",
      "Confusion Matrix: \n",
      " [[1975  151]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.92      2155\n",
      "   macro avg       0.50      0.48      0.48      2155\n",
      "weighted avg       0.97      0.92      0.94      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  65.3061224489796\n",
      "Confusion Matrix: \n",
      " [[ 62 141]\n",
      " [ 46 290]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.31      0.40       203\n",
      "           1       0.67      0.86      0.76       336\n",
      "\n",
      "    accuracy                           0.65       539\n",
      "   macro avg       0.62      0.58      0.58       539\n",
      "weighted avg       0.64      0.65      0.62       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 64.56400742115028\n",
      "Confusion Matrix: \n",
      " [[ 57 146]\n",
      " [ 45 291]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.28      0.37       203\n",
      "           1       0.67      0.87      0.75       336\n",
      "\n",
      "    accuracy                           0.65       539\n",
      "   macro avg       0.61      0.57      0.56       539\n",
      "weighted avg       0.63      0.65      0.61       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  62.64501160092807\n",
      "Confusion Matrix: \n",
      " [[ 230  635]\n",
      " [ 170 1120]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.27      0.36       865\n",
      "           1       0.64      0.87      0.74      1290\n",
      "\n",
      "    accuracy                           0.63      2155\n",
      "   macro avg       0.61      0.57      0.55      2155\n",
      "weighted avg       0.61      0.63      0.59      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 60.64965197215777\n",
      "Confusion Matrix: \n",
      " [[ 172  693]\n",
      " [ 155 1135]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.20      0.29       865\n",
      "           1       0.62      0.88      0.73      1290\n",
      "\n",
      "    accuracy                           0.61      2155\n",
      "   macro avg       0.57      0.54      0.51      2155\n",
      "weighted avg       0.58      0.61      0.55      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 84.04452690166976\n",
      "Confusion Matrix: \n",
      " [[451  57]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       508\n",
      "           1       0.03      0.06      0.04        31\n",
      "\n",
      "    accuracy                           0.84       539\n",
      "   macro avg       0.49      0.48      0.48       539\n",
      "weighted avg       0.89      0.84      0.86       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 88.35266821345708\n",
      "Confusion Matrix: \n",
      " [[1889  163]\n",
      " [  88   15]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      2052\n",
      "           1       0.08      0.15      0.11       103\n",
      "\n",
      "    accuracy                           0.88      2155\n",
      "   macro avg       0.52      0.53      0.52      2155\n",
      "weighted avg       0.91      0.88      0.90      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 30.612244897959183\n",
      "Confusion Matrix: \n",
      " [[144 364]\n",
      " [ 10  21]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.28      0.44       508\n",
      "           1       0.05      0.68      0.10        31\n",
      "\n",
      "    accuracy                           0.31       539\n",
      "   macro avg       0.49      0.48      0.27       539\n",
      "weighted avg       0.88      0.31      0.42       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 24.547563805104406\n",
      "Confusion Matrix: \n",
      " [[ 417 1603]\n",
      " [  23  112]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.21      0.34      2020\n",
      "           1       0.07      0.83      0.12       135\n",
      "\n",
      "    accuracy                           0.25      2155\n",
      "   macro avg       0.51      0.52      0.23      2155\n",
      "weighted avg       0.89      0.25      0.33      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 90.35250463821892\n",
      "Confusion Matrix: \n",
      " [[487  49]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.90       539\n",
      "   macro avg       0.50      0.45      0.47       539\n",
      "weighted avg       0.99      0.90      0.94       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 91.87935034802784\n",
      "Confusion Matrix: \n",
      " [[1979  147]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.92      2155\n",
      "   macro avg       0.50      0.48      0.48      2155\n",
      "weighted avg       0.97      0.92      0.94      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  71.79962894248608\n",
      "Confusion Matrix: \n",
      " [[142  61]\n",
      " [ 91 245]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.70      0.65       203\n",
      "           1       0.80      0.73      0.76       336\n",
      "\n",
      "    accuracy                           0.72       539\n",
      "   macro avg       0.71      0.71      0.71       539\n",
      "weighted avg       0.73      0.72      0.72       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 66.04823747680891\n",
      "Confusion Matrix: \n",
      " [[ 74 129]\n",
      " [ 54 282]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.36      0.45       203\n",
      "           1       0.69      0.84      0.76       336\n",
      "\n",
      "    accuracy                           0.66       539\n",
      "   macro avg       0.63      0.60      0.60       539\n",
      "weighted avg       0.65      0.66      0.64       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  69.04872389791183\n",
      "Confusion Matrix: \n",
      " [[511 354]\n",
      " [313 977]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.61       865\n",
      "           1       0.73      0.76      0.75      1290\n",
      "\n",
      "    accuracy                           0.69      2155\n",
      "   macro avg       0.68      0.67      0.68      2155\n",
      "weighted avg       0.69      0.69      0.69      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 62.32018561484919\n",
      "Confusion Matrix: \n",
      " [[ 234  631]\n",
      " [ 181 1109]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.27      0.37       865\n",
      "           1       0.64      0.86      0.73      1290\n",
      "\n",
      "    accuracy                           0.62      2155\n",
      "   macro avg       0.60      0.57      0.55      2155\n",
      "weighted avg       0.61      0.62      0.58      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 84.2300556586271\n",
      "Confusion Matrix: \n",
      " [[452  56]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       508\n",
      "           1       0.03      0.06      0.04        31\n",
      "\n",
      "    accuracy                           0.84       539\n",
      "   macro avg       0.49      0.48      0.48       539\n",
      "weighted avg       0.89      0.84      0.86       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 88.584686774942\n",
      "Confusion Matrix: \n",
      " [[1895  157]\n",
      " [  89   14]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      2052\n",
      "           1       0.08      0.14      0.10       103\n",
      "\n",
      "    accuracy                           0.89      2155\n",
      "   macro avg       0.52      0.53      0.52      2155\n",
      "weighted avg       0.91      0.89      0.90      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 37.66233766233766\n",
      "Confusion Matrix: \n",
      " [[182 326]\n",
      " [ 10  21]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.36      0.52       508\n",
      "           1       0.06      0.68      0.11        31\n",
      "\n",
      "    accuracy                           0.38       539\n",
      "   macro avg       0.50      0.52      0.32       539\n",
      "weighted avg       0.90      0.38      0.50       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 26.12529002320186\n",
      "Confusion Matrix: \n",
      " [[ 453 1567]\n",
      " [  25  110]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.22      0.36      2020\n",
      "           1       0.07      0.81      0.12       135\n",
      "\n",
      "    accuracy                           0.26      2155\n",
      "   macro avg       0.51      0.52      0.24      2155\n",
      "weighted avg       0.89      0.26      0.35      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 90.9090909090909\n",
      "Confusion Matrix: \n",
      " [[490  46]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       539\n",
      "   macro avg       0.50      0.46      0.48       539\n",
      "weighted avg       0.99      0.91      0.95       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 92.06496519721577\n",
      "Confusion Matrix: \n",
      " [[1983  143]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.92      2155\n",
      "   macro avg       0.50      0.48      0.49      2155\n",
      "weighted avg       0.97      0.92      0.95      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  55.473098330241186\n",
      "Confusion Matrix: \n",
      " [[202   1]\n",
      " [239  97]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      1.00      0.63       203\n",
      "           1       0.99      0.29      0.45       336\n",
      "\n",
      "    accuracy                           0.55       539\n",
      "   macro avg       0.72      0.64      0.54       539\n",
      "weighted avg       0.79      0.55      0.51       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 67.90352504638219\n",
      "Confusion Matrix: \n",
      " [[101 102]\n",
      " [ 71 265]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.50      0.54       203\n",
      "           1       0.72      0.79      0.75       336\n",
      "\n",
      "    accuracy                           0.68       539\n",
      "   macro avg       0.65      0.64      0.65       539\n",
      "weighted avg       0.67      0.68      0.67       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  59.21113689095128\n",
      "Confusion Matrix: \n",
      " [[833  32]\n",
      " [847 443]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.96      0.65       865\n",
      "           1       0.93      0.34      0.50      1290\n",
      "\n",
      "    accuracy                           0.59      2155\n",
      "   macro avg       0.71      0.65      0.58      2155\n",
      "weighted avg       0.76      0.59      0.56      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rude Accuracy score(train data with multiple features): 64.45475638051043\n",
      "Confusion Matrix: \n",
      " [[ 346  519]\n",
      " [ 247 1043]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.40      0.47       865\n",
      "           1       0.67      0.81      0.73      1290\n",
      "\n",
      "    accuracy                           0.64      2155\n",
      "   macro avg       0.63      0.60      0.60      2155\n",
      "weighted avg       0.63      0.64      0.63      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 84.2300556586271\n",
      "Confusion Matrix: \n",
      " [[452  56]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       508\n",
      "           1       0.03      0.06      0.04        31\n",
      "\n",
      "    accuracy                           0.84       539\n",
      "   macro avg       0.49      0.48      0.48       539\n",
      "weighted avg       0.89      0.84      0.86       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 88.63109048723898\n",
      "Confusion Matrix: \n",
      " [[1896  156]\n",
      " [  89   14]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      2052\n",
      "           1       0.08      0.14      0.10       103\n",
      "\n",
      "    accuracy                           0.89      2155\n",
      "   macro avg       0.52      0.53      0.52      2155\n",
      "weighted avg       0.91      0.89      0.90      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 41.929499072356215\n",
      "Confusion Matrix: \n",
      " [[206 302]\n",
      " [ 11  20]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.41      0.57       508\n",
      "           1       0.06      0.65      0.11        31\n",
      "\n",
      "    accuracy                           0.42       539\n",
      "   macro avg       0.51      0.53      0.34       539\n",
      "weighted avg       0.90      0.42      0.54       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 28.25986078886311\n",
      "Confusion Matrix: \n",
      " [[ 500 1520]\n",
      " [  26  109]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.25      0.39      2020\n",
      "           1       0.07      0.81      0.12       135\n",
      "\n",
      "    accuracy                           0.28      2155\n",
      "   macro avg       0.51      0.53      0.26      2155\n",
      "weighted avg       0.90      0.28      0.38      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 91.09461966604823\n",
      "Confusion Matrix: \n",
      " [[491  45]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       539\n",
      "   macro avg       0.50      0.46      0.48       539\n",
      "weighted avg       0.99      0.91      0.95       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 92.15777262180974\n",
      "Confusion Matrix: \n",
      " [[1985  141]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.92      2155\n",
      "   macro avg       0.50      0.48      0.49      2155\n",
      "weighted avg       0.97      0.92      0.95      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  40.44526901669759\n",
      "Confusion Matrix: \n",
      " [[203   0]\n",
      " [321  15]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      1.00      0.56       203\n",
      "           1       1.00      0.04      0.09       336\n",
      "\n",
      "    accuracy                           0.40       539\n",
      "   macro avg       0.69      0.52      0.32       539\n",
      "weighted avg       0.77      0.40      0.26       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 67.71799628942486\n",
      "Confusion Matrix: \n",
      " [[159  44]\n",
      " [130 206]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.78      0.65       203\n",
      "           1       0.82      0.61      0.70       336\n",
      "\n",
      "    accuracy                           0.68       539\n",
      "   macro avg       0.69      0.70      0.67       539\n",
      "weighted avg       0.72      0.68      0.68       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  42.78422273781903\n",
      "Confusion Matrix: \n",
      " [[ 862    3]\n",
      " [1230   60]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      1.00      0.58       865\n",
      "           1       0.95      0.05      0.09      1290\n",
      "\n",
      "    accuracy                           0.43      2155\n",
      "   macro avg       0.68      0.52      0.34      2155\n",
      "weighted avg       0.74      0.43      0.29      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 66.45011600928075\n",
      "Confusion Matrix: \n",
      " [[544 321]\n",
      " [402 888]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.63      0.60       865\n",
      "           1       0.73      0.69      0.71      1290\n",
      "\n",
      "    accuracy                           0.66      2155\n",
      "   macro avg       0.65      0.66      0.66      2155\n",
      "weighted avg       0.67      0.66      0.67      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 84.78664192949907\n",
      "Confusion Matrix: \n",
      " [[455  53]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       508\n",
      "           1       0.04      0.06      0.05        31\n",
      "\n",
      "    accuracy                           0.85       539\n",
      "   macro avg       0.49      0.48      0.48       539\n",
      "weighted avg       0.89      0.85      0.87       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 88.81670533642692\n",
      "Confusion Matrix: \n",
      " [[1900  152]\n",
      " [  89   14]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      2052\n",
      "           1       0.08      0.14      0.10       103\n",
      "\n",
      "    accuracy                           0.89      2155\n",
      "   macro avg       0.52      0.53      0.52      2155\n",
      "weighted avg       0.91      0.89      0.90      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 55.84415584415584\n",
      "Confusion Matrix: \n",
      " [[283 225]\n",
      " [ 13  18]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.56      0.70       508\n",
      "           1       0.07      0.58      0.13        31\n",
      "\n",
      "    accuracy                           0.56       539\n",
      "   macro avg       0.52      0.57      0.42       539\n",
      "weighted avg       0.91      0.56      0.67       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 33.96751740139211\n",
      "Confusion Matrix: \n",
      " [[ 632 1388]\n",
      " [  35  100]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.31      0.47      2020\n",
      "           1       0.07      0.74      0.12       135\n",
      "\n",
      "    accuracy                           0.34      2155\n",
      "   macro avg       0.51      0.53      0.30      2155\n",
      "weighted avg       0.89      0.34      0.45      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 91.09461966604823\n",
      "Confusion Matrix: \n",
      " [[491  45]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       539\n",
      "   macro avg       0.50      0.46      0.48       539\n",
      "weighted avg       0.99      0.91      0.95       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 92.52900232018561\n",
      "Confusion Matrix: \n",
      " [[1993  133]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.93      2155\n",
      "   macro avg       0.50      0.49      0.49      2155\n",
      "weighted avg       0.97      0.93      0.95      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  37.66233766233766\n",
      "Confusion Matrix: \n",
      " [[203   0]\n",
      " [336   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      1.00      0.55       203\n",
      "           1       0.00      0.00      0.00       336\n",
      "\n",
      "    accuracy                           0.38       539\n",
      "   macro avg       0.19      0.50      0.27       539\n",
      "weighted avg       0.14      0.38      0.21       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 37.66233766233766\n",
      "Confusion Matrix: \n",
      " [[203   0]\n",
      " [336   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      1.00      0.55       203\n",
      "           1       0.00      0.00      0.00       336\n",
      "\n",
      "    accuracy                           0.38       539\n",
      "   macro avg       0.19      0.50      0.27       539\n",
      "weighted avg       0.14      0.38      0.21       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  40.13921113689095\n",
      "Confusion Matrix: \n",
      " [[ 865    0]\n",
      " [1290    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      1.00      0.57       865\n",
      "           1       0.00      0.00      0.00      1290\n",
      "\n",
      "    accuracy                           0.40      2155\n",
      "   macro avg       0.20      0.50      0.29      2155\n",
      "weighted avg       0.16      0.40      0.23      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 40.13921113689095\n",
      "Confusion Matrix: \n",
      " [[ 865    0]\n",
      " [1290    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      1.00      0.57       865\n",
      "           1       0.00      0.00      0.00      1290\n",
      "\n",
      "    accuracy                           0.40      2155\n",
      "   macro avg       0.20      0.50      0.29      2155\n",
      "weighted avg       0.16      0.40      0.23      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 89.98144712430427\n",
      "Confusion Matrix: \n",
      " [[484  24]\n",
      " [ 30   1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       508\n",
      "           1       0.04      0.03      0.04        31\n",
      "\n",
      "    accuracy                           0.90       539\n",
      "   macro avg       0.49      0.49      0.49       539\n",
      "weighted avg       0.89      0.90      0.89       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 91.64733178654292\n",
      "Confusion Matrix: \n",
      " [[1967   85]\n",
      " [  95    8]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96      2052\n",
      "           1       0.09      0.08      0.08       103\n",
      "\n",
      "    accuracy                           0.92      2155\n",
      "   macro avg       0.52      0.52      0.52      2155\n",
      "weighted avg       0.91      0.92      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 96.66048237476808\n",
      "Confusion Matrix: \n",
      " [[521  15]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.97       539\n",
      "   macro avg       0.50      0.49      0.49       539\n",
      "weighted avg       0.99      0.97      0.98       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 95.82366589327145\n",
      "Confusion Matrix: \n",
      " [[2064   62]\n",
      " [  28    1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      2126\n",
      "           1       0.02      0.03      0.02        29\n",
      "\n",
      "    accuracy                           0.96      2155\n",
      "   macro avg       0.50      0.50      0.50      2155\n",
      "weighted avg       0.97      0.96      0.97      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Naive bays\n",
    "import numpy\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#ensemble model of comments feature and context feature\n",
    "abusive_type = [\"Rude\",\"Figurative\",\"Offensive\",\"Dirty\"]\n",
    "report=[]\n",
    "for threshold in numpy.arange(0.1,1.1,0.1):\n",
    "    for i in range(0,4):\n",
    "        Naive_bayes_1 = MultinomialNB()\n",
    "        Naive_bayes_2 = MultinomialNB()\n",
    "\n",
    "        Naive_bayes_1.fit(train_feat_content, Train_Y[abusive_type[i]])\n",
    "        Naive_bayes_2.fit(train_feat_context, Train_Y[abusive_type[i]])\n",
    "\n",
    "        predictions_NB_Train1 = Naive_bayes_1.predict_proba(train_feat_content)\n",
    "        predictions_NB_Train2 = Naive_bayes_2.predict_proba(train_feat_context)\n",
    "\n",
    "        predictions_NB_Test1 = Naive_bayes_1.predict_proba(test_feat_content)\n",
    "        predictions_NB_Test2 = Naive_bayes_2.predict_proba(test_feat_context)\n",
    "\n",
    "        predictions_NB_Train = (predictions_NB_Train1+predictions_NB_Train2)/2\n",
    "        predictions_NB_Test = (predictions_NB_Test1+predictions_NB_Test2)/2\n",
    "\n",
    "        predictions_class_Train = predict_class(predictions_NB_Train,threshold)\n",
    "        predictions_class_Test = predict_class(predictions_NB_Test,threshold)\n",
    "\n",
    "        #combine multiple feature with one model\n",
    "        Naive_bayes_3 = MultinomialNB()\n",
    "        Naive_bayes_3.fit(train_feat, Train_Y[abusive_type[i]])\n",
    "        predictions_NB_Train3 = Naive_bayes_3.predict_proba(train_feat)\n",
    "        predictions_NB_Test3 = Naive_bayes_3.predict_proba(test_feat)\n",
    "\n",
    "        predictions_class_Train_c = (predictions_NB_Train3 [:,1] >= threshold).astype('int')\n",
    "        predictions_class_Test_c = (predictions_NB_Test3 [:,1] >= threshold).astype('int')\n",
    "        report_performance(predictions_class_Train, predictions_class_Test, predictions_class_Train_c,predictions_class_Test_c, abusive_type[i],threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  63.4508348794063\n",
      "Confusion Matrix: \n",
      " [[ 25 178]\n",
      " [ 19 317]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.12      0.20       203\n",
      "           1       0.64      0.94      0.76       336\n",
      "\n",
      "    accuracy                           0.63       539\n",
      "   macro avg       0.60      0.53      0.48       539\n",
      "weighted avg       0.61      0.63      0.55       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  59.62877030162414\n",
      "Confusion Matrix: \n",
      " [[  70  795]\n",
      " [  75 1215]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.08      0.14       865\n",
      "           1       0.60      0.94      0.74      1290\n",
      "\n",
      "    accuracy                           0.60      2155\n",
      "   macro avg       0.54      0.51      0.44      2155\n",
      "weighted avg       0.56      0.60      0.50      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  82.56029684601113\n",
      "Confusion Matrix: \n",
      " [[443  65]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90       508\n",
      "           1       0.03      0.06      0.04        31\n",
      "\n",
      "    accuracy                           0.83       539\n",
      "   macro avg       0.48      0.47      0.47       539\n",
      "weighted avg       0.89      0.83      0.85       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  85.4292343387471\n",
      "Confusion Matrix: \n",
      " [[1818  234]\n",
      " [  80   23]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      2052\n",
      "           1       0.09      0.22      0.13       103\n",
      "\n",
      "    accuracy                           0.85      2155\n",
      "   macro avg       0.52      0.55      0.52      2155\n",
      "weighted avg       0.92      0.85      0.88      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  22.820037105751393\n",
      "Confusion Matrix: \n",
      " [[ 97 411]\n",
      " [  5  26]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.19      0.32       508\n",
      "           1       0.06      0.84      0.11        31\n",
      "\n",
      "    accuracy                           0.23       539\n",
      "   macro avg       0.51      0.51      0.21       539\n",
      "weighted avg       0.90      0.23      0.31       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  21.809744779582367\n",
      "Confusion Matrix: \n",
      " [[ 356 1664]\n",
      " [  21  114]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.18      0.30      2020\n",
      "           1       0.06      0.84      0.12       135\n",
      "\n",
      "    accuracy                           0.22      2155\n",
      "   macro avg       0.50      0.51      0.21      2155\n",
      "weighted avg       0.89      0.22      0.29      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  89.98144712430427\n",
      "Confusion Matrix: \n",
      " [[485  51]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.95       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.90       539\n",
      "   macro avg       0.50      0.45      0.47       539\n",
      "weighted avg       0.99      0.90      0.94       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  90.8584686774942\n",
      "Confusion Matrix: \n",
      " [[1956  170]\n",
      " [  27    2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      2126\n",
      "           1       0.01      0.07      0.02        29\n",
      "\n",
      "    accuracy                           0.91      2155\n",
      "   macro avg       0.50      0.49      0.49      2155\n",
      "weighted avg       0.97      0.91      0.94      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  63.63636363636363\n",
      "Confusion Matrix: \n",
      " [[ 28 175]\n",
      " [ 21 315]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.14      0.22       203\n",
      "           1       0.64      0.94      0.76       336\n",
      "\n",
      "    accuracy                           0.64       539\n",
      "   macro avg       0.61      0.54      0.49       539\n",
      "weighted avg       0.62      0.64      0.56       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  59.53596287703016\n",
      "Confusion Matrix: \n",
      " [[  78  787]\n",
      " [  85 1205]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.09      0.15       865\n",
      "           1       0.60      0.93      0.73      1290\n",
      "\n",
      "    accuracy                           0.60      2155\n",
      "   macro avg       0.54      0.51      0.44      2155\n",
      "weighted avg       0.55      0.60      0.50      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  83.85899814471243\n",
      "Confusion Matrix: \n",
      " [[450  58]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       508\n",
      "           1       0.03      0.06      0.04        31\n",
      "\n",
      "    accuracy                           0.84       539\n",
      "   macro avg       0.49      0.48      0.48       539\n",
      "weighted avg       0.89      0.84      0.86       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  86.58932714617168\n",
      "Confusion Matrix: \n",
      " [[1846  206]\n",
      " [  83   20]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      2052\n",
      "           1       0.09      0.19      0.12       103\n",
      "\n",
      "    accuracy                           0.87      2155\n",
      "   macro avg       0.52      0.55      0.52      2155\n",
      "weighted avg       0.92      0.87      0.89      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  24.489795918367346\n",
      "Confusion Matrix: \n",
      " [[107 401]\n",
      " [  6  25]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.21      0.34       508\n",
      "           1       0.06      0.81      0.11        31\n",
      "\n",
      "    accuracy                           0.24       539\n",
      "   macro avg       0.50      0.51      0.23       539\n",
      "weighted avg       0.90      0.24      0.33       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  24.872389791183295\n",
      "Confusion Matrix: \n",
      " [[ 425 1595]\n",
      " [  24  111]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.21      0.34      2020\n",
      "           1       0.07      0.82      0.12       135\n",
      "\n",
      "    accuracy                           0.25      2155\n",
      "   macro avg       0.51      0.52      0.23      2155\n",
      "weighted avg       0.89      0.25      0.33      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  91.28014842300557\n",
      "Confusion Matrix: \n",
      " [[492  44]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       539\n",
      "   macro avg       0.50      0.46      0.48       539\n",
      "weighted avg       0.99      0.91      0.95       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  91.46171693735499\n",
      "Confusion Matrix: \n",
      " [[1970  156]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.91      2155\n",
      "   macro avg       0.50      0.48      0.48      2155\n",
      "weighted avg       0.97      0.91      0.94      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  63.07977736549165\n",
      "Confusion Matrix: \n",
      " [[ 30 173]\n",
      " [ 26 310]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.15      0.23       203\n",
      "           1       0.64      0.92      0.76       336\n",
      "\n",
      "    accuracy                           0.63       539\n",
      "   macro avg       0.59      0.54      0.49       539\n",
      "weighted avg       0.60      0.63      0.56       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  59.303944315545245\n",
      "Confusion Matrix: \n",
      " [[  89  776]\n",
      " [ 101 1189]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.10      0.17       865\n",
      "           1       0.61      0.92      0.73      1290\n",
      "\n",
      "    accuracy                           0.59      2155\n",
      "   macro avg       0.54      0.51      0.45      2155\n",
      "weighted avg       0.55      0.59      0.51      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  84.60111317254174\n",
      "Confusion Matrix: \n",
      " [[454  54]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92       508\n",
      "           1       0.04      0.06      0.05        31\n",
      "\n",
      "    accuracy                           0.85       539\n",
      "   macro avg       0.49      0.48      0.48       539\n",
      "weighted avg       0.89      0.85      0.87       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  87.28538283062645\n",
      "Confusion Matrix: \n",
      " [[1863  189]\n",
      " [  85   18]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      2052\n",
      "           1       0.09      0.17      0.12       103\n",
      "\n",
      "    accuracy                           0.87      2155\n",
      "   macro avg       0.52      0.54      0.52      2155\n",
      "weighted avg       0.91      0.87      0.89      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  26.53061224489796\n",
      "Confusion Matrix: \n",
      " [[119 389]\n",
      " [  7  24]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.23      0.38       508\n",
      "           1       0.06      0.77      0.11        31\n",
      "\n",
      "    accuracy                           0.27       539\n",
      "   macro avg       0.50      0.50      0.24       539\n",
      "weighted avg       0.89      0.27      0.36       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  26.77494199535963\n",
      "Confusion Matrix: \n",
      " [[ 467 1553]\n",
      " [  25  110]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.23      0.37      2020\n",
      "           1       0.07      0.81      0.12       135\n",
      "\n",
      "    accuracy                           0.27      2155\n",
      "   macro avg       0.51      0.52      0.25      2155\n",
      "weighted avg       0.89      0.27      0.36      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  91.4656771799629\n",
      "Confusion Matrix: \n",
      " [[493  43]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       539\n",
      "   macro avg       0.50      0.46      0.48       539\n",
      "weighted avg       0.99      0.91      0.95       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  92.06496519721577\n",
      "Confusion Matrix: \n",
      " [[1983  143]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.92      2155\n",
      "   macro avg       0.50      0.48      0.49      2155\n",
      "weighted avg       0.97      0.92      0.95      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  62.708719851577\n",
      "Confusion Matrix: \n",
      " [[ 33 170]\n",
      " [ 31 305]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.16      0.25       203\n",
      "           1       0.64      0.91      0.75       336\n",
      "\n",
      "    accuracy                           0.63       539\n",
      "   macro avg       0.58      0.54      0.50       539\n",
      "weighted avg       0.59      0.63      0.56       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  59.58236658932715\n",
      "Confusion Matrix: \n",
      " [[ 105  760]\n",
      " [ 111 1179]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.12      0.19       865\n",
      "           1       0.61      0.91      0.73      1290\n",
      "\n",
      "    accuracy                           0.60      2155\n",
      "   macro avg       0.55      0.52      0.46      2155\n",
      "weighted avg       0.56      0.60      0.52      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  84.97217068645641\n",
      "Confusion Matrix: \n",
      " [[456  52]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       508\n",
      "           1       0.04      0.06      0.05        31\n",
      "\n",
      "    accuracy                           0.85       539\n",
      "   macro avg       0.49      0.48      0.48       539\n",
      "weighted avg       0.89      0.85      0.87       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  87.93503480278422\n",
      "Confusion Matrix: \n",
      " [[1877  175]\n",
      " [  85   18]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94      2052\n",
      "           1       0.09      0.17      0.12       103\n",
      "\n",
      "    accuracy                           0.88      2155\n",
      "   macro avg       0.52      0.54      0.53      2155\n",
      "weighted avg       0.92      0.88      0.90      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  32.09647495361781\n",
      "Confusion Matrix: \n",
      " [[152 356]\n",
      " [ 10  21]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.30      0.45       508\n",
      "           1       0.06      0.68      0.10        31\n",
      "\n",
      "    accuracy                           0.32       539\n",
      "   macro avg       0.50      0.49      0.28       539\n",
      "weighted avg       0.89      0.32      0.43       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  33.50348027842227\n",
      "Confusion Matrix: \n",
      " [[ 617 1403]\n",
      " [  30  105]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.31      0.46      2020\n",
      "           1       0.07      0.78      0.13       135\n",
      "\n",
      "    accuracy                           0.34      2155\n",
      "   macro avg       0.51      0.54      0.30      2155\n",
      "weighted avg       0.90      0.34      0.44      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  91.65120593692022\n",
      "Confusion Matrix: \n",
      " [[494  42]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.92       539\n",
      "   macro avg       0.50      0.46      0.48       539\n",
      "weighted avg       0.99      0.92      0.95       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  92.5754060324826\n",
      "Confusion Matrix: \n",
      " [[1994  132]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.93      2155\n",
      "   macro avg       0.50      0.49      0.49      2155\n",
      "weighted avg       0.97      0.93      0.95      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  63.07977736549165\n",
      "Confusion Matrix: \n",
      " [[ 41 162]\n",
      " [ 37 299]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.20      0.29       203\n",
      "           1       0.65      0.89      0.75       336\n",
      "\n",
      "    accuracy                           0.63       539\n",
      "   macro avg       0.59      0.55      0.52       539\n",
      "weighted avg       0.60      0.63      0.58       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  59.86078886310905\n",
      "Confusion Matrix: \n",
      " [[ 134  731]\n",
      " [ 134 1156]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.15      0.24       865\n",
      "           1       0.61      0.90      0.73      1290\n",
      "\n",
      "    accuracy                           0.60      2155\n",
      "   macro avg       0.56      0.53      0.48      2155\n",
      "weighted avg       0.57      0.60      0.53      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  86.08534322820037\n",
      "Confusion Matrix: \n",
      " [[462  46]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92       508\n",
      "           1       0.04      0.06      0.05        31\n",
      "\n",
      "    accuracy                           0.86       539\n",
      "   macro avg       0.49      0.49      0.49       539\n",
      "weighted avg       0.89      0.86      0.87       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  88.90951276102088\n",
      "Confusion Matrix: \n",
      " [[1903  149]\n",
      " [  90   13]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      2052\n",
      "           1       0.08      0.13      0.10       103\n",
      "\n",
      "    accuracy                           0.89      2155\n",
      "   macro avg       0.52      0.53      0.52      2155\n",
      "weighted avg       0.91      0.89      0.90      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  57.69944341372912\n",
      "Confusion Matrix: \n",
      " [[293 215]\n",
      " [ 13  18]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.58      0.72       508\n",
      "           1       0.08      0.58      0.14        31\n",
      "\n",
      "    accuracy                           0.58       539\n",
      "   macro avg       0.52      0.58      0.43       539\n",
      "weighted avg       0.91      0.58      0.69       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  52.43619489559165\n",
      "Confusion Matrix: \n",
      " [[1042  978]\n",
      " [  47   88]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.52      0.67      2020\n",
      "           1       0.08      0.65      0.15       135\n",
      "\n",
      "    accuracy                           0.52      2155\n",
      "   macro avg       0.52      0.58      0.41      2155\n",
      "weighted avg       0.90      0.52      0.64      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.06307977736549\n",
      "Confusion Matrix: \n",
      " [[507  29]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.50      0.47      0.48       539\n",
      "weighted avg       0.99      0.94      0.96       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  94.06032482598607\n",
      "Confusion Matrix: \n",
      " [[2026  100]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      2126\n",
      "           1       0.01      0.03      0.02        29\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.50      0.49      0.49      2155\n",
      "weighted avg       0.97      0.94      0.96      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  70.12987012987013\n",
      "Confusion Matrix: \n",
      " [[ 95 108]\n",
      " [ 53 283]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.47      0.54       203\n",
      "           1       0.72      0.84      0.78       336\n",
      "\n",
      "    accuracy                           0.70       539\n",
      "   macro avg       0.68      0.66      0.66       539\n",
      "weighted avg       0.69      0.70      0.69       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  66.5429234338747\n",
      "Confusion Matrix: \n",
      " [[ 319  546]\n",
      " [ 175 1115]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.37      0.47       865\n",
      "           1       0.67      0.86      0.76      1290\n",
      "\n",
      "    accuracy                           0.67      2155\n",
      "   macro avg       0.66      0.62      0.61      2155\n",
      "weighted avg       0.66      0.67      0.64      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  66.79035250463822\n",
      "Confusion Matrix: \n",
      " [[193  10]\n",
      " [169 167]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.95      0.68       203\n",
      "           1       0.94      0.50      0.65       336\n",
      "\n",
      "    accuracy                           0.67       539\n",
      "   macro avg       0.74      0.72      0.67       539\n",
      "weighted avg       0.79      0.67      0.66       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  67.4245939675174\n",
      "Confusion Matrix: \n",
      " [[710 155]\n",
      " [547 743]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.82      0.67       865\n",
      "           1       0.83      0.58      0.68      1290\n",
      "\n",
      "    accuracy                           0.67      2155\n",
      "   macro avg       0.70      0.70      0.67      2155\n",
      "weighted avg       0.72      0.67      0.68      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  46.567717996289424\n",
      "Confusion Matrix: \n",
      " [[203   0]\n",
      " [288  48]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      1.00      0.59       203\n",
      "           1       1.00      0.14      0.25       336\n",
      "\n",
      "    accuracy                           0.47       539\n",
      "   macro avg       0.71      0.57      0.42       539\n",
      "weighted avg       0.78      0.47      0.38       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  49.1415313225058\n",
      "Confusion Matrix: \n",
      " [[ 852   13]\n",
      " [1083  207]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.98      0.61       865\n",
      "           1       0.94      0.16      0.27      1290\n",
      "\n",
      "    accuracy                           0.49      2155\n",
      "   macro avg       0.69      0.57      0.44      2155\n",
      "weighted avg       0.74      0.49      0.41      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  39.70315398886827\n",
      "Confusion Matrix: \n",
      " [[203   0]\n",
      " [325  11]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      1.00      0.56       203\n",
      "           1       1.00      0.03      0.06       336\n",
      "\n",
      "    accuracy                           0.40       539\n",
      "   macro avg       0.69      0.52      0.31       539\n",
      "weighted avg       0.77      0.40      0.25       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  42.04176334106728\n",
      "Confusion Matrix: \n",
      " [[ 863    2]\n",
      " [1247   43]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      1.00      0.58       865\n",
      "           1       0.96      0.03      0.06      1290\n",
      "\n",
      "    accuracy                           0.42      2155\n",
      "   macro avg       0.68      0.52      0.32      2155\n",
      "weighted avg       0.74      0.42      0.27      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  37.66233766233766\n",
      "Confusion Matrix: \n",
      " [[203   0]\n",
      " [336   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      1.00      0.55       203\n",
      "           1       0.00      0.00      0.00       336\n",
      "\n",
      "    accuracy                           0.38       539\n",
      "   macro avg       0.19      0.50      0.27       539\n",
      "weighted avg       0.14      0.38      0.21       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  40.13921113689095\n",
      "Confusion Matrix: \n",
      " [[ 865    0]\n",
      " [1290    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      1.00      0.57       865\n",
      "           1       0.00      0.00      0.00      1290\n",
      "\n",
      "    accuracy                           0.40      2155\n",
      "   macro avg       0.20      0.50      0.29      2155\n",
      "weighted avg       0.16      0.40      0.23      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Naive bays\n",
    "import numpy\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#P=threshold*(content)+(1-threshold)*(context)\n",
    "#ensemble model of comments feature and context feature\n",
    "abusive_type = [\"Rude\",\"Figurative\",\"Offensive\",\"Dirty\"]\n",
    "report=[]\n",
    "for threshold in numpy.arange(0.1,1.1,0.1):\n",
    "    for i in range(0,4):\n",
    "        Naive_bayes_1 = MultinomialNB()\n",
    "        Naive_bayes_2 = MultinomialNB()\n",
    "\n",
    "        Naive_bayes_1.fit(train_feat_content, Train_Y[abusive_type[i]])\n",
    "        Naive_bayes_2.fit(train_feat_context, Train_Y[abusive_type[i]])\n",
    "\n",
    "        predictions_NB_Train1 = Naive_bayes_1.predict_proba(train_feat_content)\n",
    "        predictions_NB_Train2 = Naive_bayes_2.predict_proba(train_feat_context)\n",
    "\n",
    "        predictions_NB_Test1 = Naive_bayes_1.predict_proba(test_feat_content)\n",
    "        predictions_NB_Test2 = Naive_bayes_2.predict_proba(test_feat_context)\n",
    "\n",
    "        predictions_NB_Train = (predictions_NB_Train1*threshold)+(predictions_NB_Train2*(1-threshold))\n",
    "        predictions_NB_Test = (predictions_NB_Test1*threshold)+(predictions_NB_Test2*(1-threshold))\n",
    "\n",
    "        predictions_class_Train = predict_class(predictions_NB_Train,threshold)\n",
    "        predictions_class_Test = predict_class(predictions_NB_Test,threshold)\n",
    "\n",
    "        report_performance_threshold_1_minus_threshold(predictions_class_Train, predictions_class_Test, abusive_type[i],threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
