{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def clean_msg(msg):\n",
    "    \n",
    "    \n",
    "    # ลบ text ที่อยู่ในวงเล็บ <> ทั้งหมด\n",
    "    msg = re.sub(r'<.*?>','', msg)\n",
    "    \n",
    "    # ลบ hashtag\n",
    "    msg = re.sub(r'#','',msg)\n",
    "    \n",
    "    # ลบ เครื่องหมายคำพูด (punctuation)\n",
    "    for c in string.punctuation:\n",
    "        msg = re.sub(r'\\{}'.format(c),'',msg)\n",
    "    \n",
    "    # ลบ separator เช่น \\n \\t\n",
    "    msg = ' '.join(msg.split())\n",
    "    \n",
    "    return msg\n",
    "\n",
    "\n",
    "\n",
    "import pythainlp\n",
    "from pythainlp import word_tokenize\n",
    "from pythainlp.corpus import wordnet\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import words\n",
    "import nltk\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "def split_word(text):\n",
    "            \n",
    "    \n",
    "    tokens = word_tokenize(text,engine='newmm')\n",
    "    \n",
    "  \n",
    "    \n",
    "    # หารากศัพท์ภาษาไทย และภาษาอังกฤษ\n",
    "    # English\n",
    "    tokens = [p_stemmer.stem(i) for i in tokens]\n",
    "    \n",
    "    # Thai\n",
    "    tokens_temp=[]\n",
    "    for i in tokens:\n",
    "        w_syn = wordnet.synsets(i)\n",
    "        if (len(w_syn)>0) and (len(w_syn[0].lemma_names('tha'))>0):\n",
    "            tokens_temp.append(w_syn[0].lemma_names('tha')[0])\n",
    "        else:\n",
    "            tokens_temp.append(i)\n",
    "    \n",
    "    tokens = tokens_temp\n",
    "    \n",
    "    # ลบตัวเลข\n",
    "    tokens = [i for i in tokens if not i.isnumeric()]\n",
    "    \n",
    "    # ลบช่องว่าง\n",
    "    tokens = [i for i in tokens if not ' ' in i]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import xlrd  \n",
    "import pandas as pd\n",
    "Corpus = pd.read_excel('corpus_comments.xlsx')\n",
    "Corpus['comments'] = Corpus['comments'].astype('str')\n",
    "Corpus['reaction_num'] = Corpus['reaction_num'].astype('float64')\n",
    "Corpus['reply_num'] = Corpus['reply_num'].astype('float64')\n",
    "Corpus['reaction1'] = Corpus['reaction1'].astype('str')\n",
    "Corpus['reaction2'] = Corpus['reaction2'].astype('str')\n",
    "Corpus['reaction3'] = Corpus['reaction3'].astype('str')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(Corpus[['comments','reaction_num','reply_num','reaction1','reaction2','reaction3']], Corpus[['Rude','Figurative','Offensive','Dirty']], test_size=0.2,random_state=1000);\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "#vectorizer = CountVectorizer()\n",
    "#vectorizer = CountVectorizer(tokenizer = split_word)\n",
    "#vectorizer.fit(Train_X)\n",
    "#vectorizer.vocabulary_\n",
    "\n",
    "#BOW\n",
    "#X_train = vectorizer.transform(Train_X).toarray()\n",
    "#X_test  = vectorizer.transform(Test_X).toarray()\n",
    "\n",
    "#Tokenizaiton\n",
    "Tfidf_vect = TfidfVectorizer(tokenizer = split_word)\n",
    "#Dictionary\n",
    "Tfidf_vect.fit(Corpus['comments'])\n",
    "#print(Tfidf_vect.vocabulary_)\n",
    "#Tf-idf\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X['comments'])\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X['comments'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from  sklearn.metrics import precision_recall_fscore_support\n",
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "\n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='weighted'))\n",
    "\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support']\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list(metrics_summary),\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    \n",
    "#     total = support.sum() \n",
    "#     avg[-1] = total\n",
    "\n",
    "#     class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "def writeEvaluation(s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12,s13,s14,s15,s16):\n",
    "    f = open(\"classification_report.csv\", mode='a')\n",
    "    f.write(s1+\",\"+s2+\",\"+s3+\",\"+s4)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(s5+\",\"+s6+\",\"+s7+\",\"+s8)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(s9+\",\"+s10+\",\"+s11+\",\"+s12)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(s13+\",\"+s14+\",\"+s15+\",\"+s16)\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "def writeEvaluation_threshold_1_minus_threshold(s1,s2,s3,s4,s5,s6,s7,s8):\n",
    "    f = open(\"classification_report.csv\", mode='a')\n",
    "    f.write(s1+\",\"+s2+\",\"+s3+\",\"+s4)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(s5+\",\"+s6+\",\"+s7+\",\"+s8)\n",
    "    f.write(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "string='';\n",
    "def report_performance(predictions_class_train, predictions_class_test, predictions_class_train_c, predictions_class_test_c, type_class,threshold):\n",
    "    #Evaluation class (test data) \n",
    "    str1 = \"Test data (ensemble)\"\n",
    "    str2 = str(threshold)\n",
    "    str3 = str(type_class)\n",
    "    str4 = str(accuracy_score(predictions_class_test, Test_Y[type_class]))\n",
    "    print(type_class+\" Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature): \",\n",
    "          accuracy_score(predictions_class_test, Test_Y[type_class])*100)\n",
    "    print(\"Confusion Matrix: \\n\", confusion_matrix(Test_Y[type_class],predictions_class_test))\n",
    "    report = classification_report(Test_Y[type_class],predictions_class_test)\n",
    "    print(\"PRF: \\n\", report)\n",
    "    \n",
    "    print(\"-----------------------------------------------------------\\n\")\n",
    "    str5 = \"Test data (multiple features)\"\n",
    "    str6 = str(threshold)\n",
    "    str7 = str(type_class)\n",
    "    str8 = str(accuracy_score(predictions_class_test_c, Test_Y[type_class]))\n",
    "    print(type_class+\" Accuracy score(test data with multiple features):\", \n",
    "          accuracy_score(predictions_class_test_c, Test_Y[type_class])*100)\n",
    "    print(\"Confusion Matrix: \\n\", confusion_matrix(Test_Y[type_class],predictions_class_test_c))\n",
    "    report = classification_report(Test_Y[type_class],predictions_class_test_c);\n",
    "    print(\"PRF: \\n\", report)\n",
    "\n",
    "    print(\"-----------------------------------------------------------\\n\")\n",
    "\n",
    "    #Evaluation class (train data)\n",
    "    str9 = \"Train data (ensemble)\"\n",
    "    str10 = str(threshold)\n",
    "    str11 = str(type_class)\n",
    "    str12 = str(accuracy_score(predictions_class_train, Train_Y[type_class]))\n",
    "    print(type_class+\" Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature): \",\n",
    "          accuracy_score(predictions_class_train, Train_Y[type_class])*100)\n",
    "    print(\"Confusion Matrix: \\n\",confusion_matrix(Train_Y[type_class],predictions_class_train))\n",
    "    print(\"PRF: \\n\",classification_report(Train_Y[type_class],predictions_class_train))\n",
    "    print(\"-----------------------------------------------------------\\n\")\n",
    "    str13 = \"Train data (mulitple features)\"\n",
    "    str14 = str(threshold)\n",
    "    str15 = str(type_class)\n",
    "    str16 = str(accuracy_score(predictions_class_train_c, Train_Y[type_class]))\n",
    "    print(type_class+\" Accuracy score(train data with multiple features):\", \n",
    "          accuracy_score(predictions_class_train_c, Train_Y[type_class])*100)\n",
    "    print(\"Confusion Matrix: \\n\",confusion_matrix(Train_Y[type_class],predictions_class_train_c))\n",
    "    print(\"PRF: \\n\",classification_report(Train_Y[type_class],predictions_class_train_c))\n",
    "    print(\"___________________________________________________________________________________________________________\\n\")\n",
    "\n",
    "    writeEvaluation(str1,str2,str3,str4,str5,str6,str7,str8,str9,str10,str11,str12,str13,str14,str15,str16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "string='';\n",
    "def report_performance_threshold_1_minus_threshold(predictions_class_train, predictions_class_test, type_class,threshold):\n",
    "     #Evaluation class (test data) \n",
    "    str1 = \"Test data ensemble(content context (threshold & 1-threshold))\"\n",
    "    str2 = str(threshold)\n",
    "    str3 = str(type_class)\n",
    "    str4 = str(accuracy_score(predictions_class_test, Test_Y[type_class]))\n",
    "    print(type_class+\" Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature): \",\n",
    "          accuracy_score(predictions_class_test, Test_Y[type_class])*100)\n",
    "    print(\"Confusion Matrix: \\n\", confusion_matrix(Test_Y[type_class],predictions_class_test))\n",
    "    report = classification_report(Test_Y[type_class],predictions_class_test)\n",
    "    print(\"PRF: \\n\", report)\n",
    "    print(\"-----------------------------------------------------------\\n\")\n",
    "    \n",
    "    #Evaluation class (train data)\n",
    "    str5 = \"Train data ensemble(content context (threshold & 1-threshold)\"\n",
    "    str6 = str(threshold)\n",
    "    str7 = str(type_class)\n",
    "    str8 = str(accuracy_score(predictions_class_train, Train_Y[type_class]))\n",
    "    print(type_class+\" Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature): \",\n",
    "          accuracy_score(predictions_class_train, Train_Y[type_class])*100)\n",
    "    print(\"Confusion Matrix: \\n\",confusion_matrix(Train_Y[type_class],predictions_class_train))\n",
    "    print(\"PRF: \\n\",classification_report(Train_Y[type_class],predictions_class_train))\n",
    "    print(\"___________________________________________________________________________________________________________\\n\")\n",
    "\n",
    "    writeEvaluation_threshold_1_minus_threshold(str1,str2,str3,str4,str5,str6,str7,str8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(list_predict_prob,threshold):\n",
    "    list_predict_class = [];\n",
    "    for i in range (len(list_predict_prob)):\n",
    "        if(list_predict_prob[i][1] > threshold):\n",
    "            list_predict_class.append(1)\n",
    "        else :\n",
    "            list_predict_class.append(0)\n",
    "    return list_predict_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeStrInReactionToNum(reaction_data=[]):\n",
    "    reaction = []\n",
    "    for i in reaction_data:\n",
    "        if(i == 'haha'):\n",
    "            reaction.append(1)\n",
    "        elif(i == 'like'):\n",
    "            reaction.append(2)\n",
    "        elif(i == 'angry'):\n",
    "            reaction.append(3)\n",
    "        elif(i == 'sad'):\n",
    "            reaction.append(4)\n",
    "        elif(i == 'wow'):\n",
    "            reaction.append(5)\n",
    "        elif(i == 'love'):\n",
    "            reaction.append(6)\n",
    "        else:\n",
    "            reaction.append(7)\n",
    "    return reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2155x5498 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 28085 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X_Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "train_reaction_num = csr_matrix(Train_X['reaction_num'].values.reshape(-1, 1))\n",
    "test_reaction_num = csr_matrix(Test_X['reaction_num'].values.reshape(-1, 1))\n",
    "train_reply_num = csr_matrix(Train_X['reply_num'].values.reshape(-1,1))\n",
    "test_reply_num = csr_matrix(Test_X['reply_num'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Train_X['reaction1'] = np.nan_to_num(0)\n",
    "# Test_X['reaction1'] = np.nan_to_num(0)\n",
    "# Train_X['reaction2'] = np.nan_to_num(0)\n",
    "# Test_X['reaction2'] = np.nan_to_num(0)\n",
    "# Train_X['reaction3'] = np.nan_to_num(0)\n",
    "# Test_X['reaction3'] = np.nan_to_num(0)\n",
    "# train_reaction1_feat = csr_matrix(Train_X['reaction1'].values.reshape(-1, 1))\n",
    "# test_reaction1_feat = csr_matrix(Test_X['reaction1'].values.reshape(-1, 1))\n",
    "# train_reaction2_feat = csr_matrix(Train_X['reaction2'].values.reshape(-1, 1))\n",
    "# test_reaction2_feat = csr_matrix(Test_X['reaction2'].values.reshape(-1, 1))\n",
    "# train_reaction3_feat = csr_matrix(Train_X['reaction3'].values.reshape(-1, 1))\n",
    "# test_reaction3_feat = csr_matrix(Test_X['reaction3'].values.reshape(-1, 1))\n",
    "train_reaction1 = changeStrInReactionToNum(Train_X['reaction1'])\n",
    "test_reaction1 = changeStrInReactionToNum(Test_X['reaction1'])\n",
    "train_reaction2 = changeStrInReactionToNum(Train_X['reaction2'])\n",
    "test_reaction2 =  changeStrInReactionToNum(Test_X['reaction2'])\n",
    "train_reaction3 = changeStrInReactionToNum(Train_X['reaction3'])\n",
    "test_reaction3=  changeStrInReactionToNum(Test_X['reaction3'])\n",
    "\n",
    "train_reaction1_feat = csr_matrix(train_reaction1).reshape(-1,1)\n",
    "test_reaction1_feat = csr_matrix(test_reaction1).reshape(-1,1)\n",
    "train_reaction2_feat = csr_matrix(train_reaction2).reshape(-1,1)\n",
    "test_reaction2_feat = csr_matrix(test_reaction2).reshape(-1,1)\n",
    "train_reaction3_feat = csr_matrix(train_reaction3).reshape(-1,1)\n",
    "test_reaction3_feat = csr_matrix(test_reaction3).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, csr_matrix\n",
    "train_feat = hstack([Train_X_Tfidf, train_reaction_num, train_reply_num, train_reaction1_feat, train_reaction2_feat, train_reaction3_feat])\n",
    "test_feat = hstack([Test_X_Tfidf, test_reaction_num, test_reply_num, test_reaction1_feat, test_reaction2_feat, test_reaction3_feat])\n",
    "train_feat_context = hstack([train_reaction_num, train_reply_num, train_reaction1_feat, train_reaction2_feat, train_reaction3_feat])\n",
    "test_feat_context = hstack([test_reaction_num, test_reply_num, test_reaction1_feat, test_reaction2_feat, test_reaction3_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  63.4508348794063\n",
      "Confusion Matrix: \n",
      " [[  6 197]\n",
      " [  0 336]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.06       203\n",
      "           1       0.63      1.00      0.77       336\n",
      "\n",
      "    accuracy                           0.63       539\n",
      "   macro avg       0.82      0.51      0.42       539\n",
      "weighted avg       0.77      0.63      0.50       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 64.56400742115028\n",
      "Confusion Matrix: \n",
      " [[ 27 176]\n",
      " [ 15 321]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.13      0.22       203\n",
      "           1       0.65      0.96      0.77       336\n",
      "\n",
      "    accuracy                           0.65       539\n",
      "   macro avg       0.64      0.54      0.50       539\n",
      "weighted avg       0.64      0.65      0.56       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  60.278422273781906\n",
      "Confusion Matrix: \n",
      " [[   9  856]\n",
      " [   0 1290]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02       865\n",
      "           1       0.60      1.00      0.75      1290\n",
      "\n",
      "    accuracy                           0.60      2155\n",
      "   macro avg       0.80      0.51      0.39      2155\n",
      "weighted avg       0.76      0.60      0.46      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 61.4385150812065\n",
      "Confusion Matrix: \n",
      " [[  96  769]\n",
      " [  62 1228]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.11      0.19       865\n",
      "           1       0.61      0.95      0.75      1290\n",
      "\n",
      "    accuracy                           0.61      2155\n",
      "   macro avg       0.61      0.53      0.47      2155\n",
      "weighted avg       0.61      0.61      0.52      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  83.30241187384044\n",
      "Confusion Matrix: \n",
      " [[447  61]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91       508\n",
      "           1       0.03      0.06      0.04        31\n",
      "\n",
      "    accuracy                           0.83       539\n",
      "   macro avg       0.49      0.47      0.48       539\n",
      "weighted avg       0.89      0.83      0.86       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  86.45011600928075\n",
      "Confusion Matrix: \n",
      " [[1841  211]\n",
      " [  81   22]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      2052\n",
      "           1       0.09      0.21      0.13       103\n",
      "\n",
      "    accuracy                           0.86      2155\n",
      "   macro avg       0.53      0.56      0.53      2155\n",
      "weighted avg       0.92      0.86      0.89      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  23.933209647495364\n",
      "Confusion Matrix: \n",
      " [[104 404]\n",
      " [  6  25]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.20      0.34       508\n",
      "           1       0.06      0.81      0.11        31\n",
      "\n",
      "    accuracy                           0.24       539\n",
      "   macro avg       0.50      0.51      0.22       539\n",
      "weighted avg       0.89      0.24      0.32       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  23.851508120649655\n",
      "Confusion Matrix: \n",
      " [[ 402 1618]\n",
      " [  23  112]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.20      0.33      2020\n",
      "           1       0.06      0.83      0.12       135\n",
      "\n",
      "    accuracy                           0.24      2155\n",
      "   macro avg       0.51      0.51      0.22      2155\n",
      "weighted avg       0.89      0.24      0.32      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  91.28014842300557\n",
      "Confusion Matrix: \n",
      " [[492  44]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       539\n",
      "   macro avg       0.50      0.46      0.48       539\n",
      "weighted avg       0.99      0.91      0.95       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  91.32250580046404\n",
      "Confusion Matrix: \n",
      " [[1967  159]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.95      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.91      2155\n",
      "   macro avg       0.50      0.48      0.48      2155\n",
      "weighted avg       0.97      0.91      0.94      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  63.821892393320965\n",
      "Confusion Matrix: \n",
      " [[  8 195]\n",
      " [  0 336]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.04      0.08       203\n",
      "           1       0.63      1.00      0.78       336\n",
      "\n",
      "    accuracy                           0.64       539\n",
      "   macro avg       0.82      0.52      0.43       539\n",
      "weighted avg       0.77      0.64      0.51       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 66.60482374768088\n",
      "Confusion Matrix: \n",
      " [[ 40 163]\n",
      " [ 17 319]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.20      0.31       203\n",
      "           1       0.66      0.95      0.78       336\n",
      "\n",
      "    accuracy                           0.67       539\n",
      "   macro avg       0.68      0.57      0.54       539\n",
      "weighted avg       0.68      0.67      0.60       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  61.16009280742459\n",
      "Confusion Matrix: \n",
      " [[  28  837]\n",
      " [   0 1290]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.06       865\n",
      "           1       0.61      1.00      0.76      1290\n",
      "\n",
      "    accuracy                           0.61      2155\n",
      "   macro avg       0.80      0.52      0.41      2155\n",
      "weighted avg       0.76      0.61      0.48      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 63.89791183294664\n",
      "Confusion Matrix: \n",
      " [[ 155  710]\n",
      " [  68 1222]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.18      0.28       865\n",
      "           1       0.63      0.95      0.76      1290\n",
      "\n",
      "    accuracy                           0.64      2155\n",
      "   macro avg       0.66      0.56      0.52      2155\n",
      "weighted avg       0.66      0.64      0.57      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  84.60111317254174\n",
      "Confusion Matrix: \n",
      " [[454  54]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92       508\n",
      "           1       0.04      0.06      0.05        31\n",
      "\n",
      "    accuracy                           0.85       539\n",
      "   macro avg       0.49      0.48      0.48       539\n",
      "weighted avg       0.89      0.85      0.87       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  87.23897911832947\n",
      "Confusion Matrix: \n",
      " [[1862  190]\n",
      " [  85   18]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      2052\n",
      "           1       0.09      0.17      0.12       103\n",
      "\n",
      "    accuracy                           0.87      2155\n",
      "   macro avg       0.52      0.54      0.52      2155\n",
      "weighted avg       0.91      0.87      0.89      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  26.159554730983302\n",
      "Confusion Matrix: \n",
      " [[117 391]\n",
      " [  7  24]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.23      0.37       508\n",
      "           1       0.06      0.77      0.11        31\n",
      "\n",
      "    accuracy                           0.26       539\n",
      "   macro avg       0.50      0.50      0.24       539\n",
      "weighted avg       0.89      0.26      0.36       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  26.54292343387471\n",
      "Confusion Matrix: \n",
      " [[ 462 1558]\n",
      " [  25  110]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.23      0.37      2020\n",
      "           1       0.07      0.81      0.12       135\n",
      "\n",
      "    accuracy                           0.27      2155\n",
      "   macro avg       0.51      0.52      0.25      2155\n",
      "weighted avg       0.89      0.27      0.35      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  91.4656771799629\n",
      "Confusion Matrix: \n",
      " [[493  43]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       539\n",
      "   macro avg       0.50      0.46      0.48       539\n",
      "weighted avg       0.99      0.91      0.95       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  92.01856148491879\n",
      "Confusion Matrix: \n",
      " [[1982  144]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.92      2155\n",
      "   macro avg       0.50      0.48      0.48      2155\n",
      "weighted avg       0.97      0.92      0.95      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  65.86270871985158\n",
      "Confusion Matrix: \n",
      " [[ 19 184]\n",
      " [  0 336]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.09      0.17       203\n",
      "           1       0.65      1.00      0.79       336\n",
      "\n",
      "    accuracy                           0.66       539\n",
      "   macro avg       0.82      0.55      0.48       539\n",
      "weighted avg       0.78      0.66      0.55       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 66.97588126159555\n",
      "Confusion Matrix: \n",
      " [[ 43 160]\n",
      " [ 18 318]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.21      0.33       203\n",
      "           1       0.67      0.95      0.78       336\n",
      "\n",
      "    accuracy                           0.67       539\n",
      "   macro avg       0.69      0.58      0.55       539\n",
      "weighted avg       0.68      0.67      0.61       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  63.248259860788856\n",
      "Confusion Matrix: \n",
      " [[  73  792]\n",
      " [   0 1290]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.08      0.16       865\n",
      "           1       0.62      1.00      0.77      1290\n",
      "\n",
      "    accuracy                           0.63      2155\n",
      "   macro avg       0.81      0.54      0.46      2155\n",
      "weighted avg       0.77      0.63      0.52      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 64.2691415313225\n",
      "Confusion Matrix: \n",
      " [[ 174  691]\n",
      " [  79 1211]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.20      0.31       865\n",
      "           1       0.64      0.94      0.76      1290\n",
      "\n",
      "    accuracy                           0.64      2155\n",
      "   macro avg       0.66      0.57      0.54      2155\n",
      "weighted avg       0.66      0.64      0.58      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  84.97217068645641\n",
      "Confusion Matrix: \n",
      " [[456  52]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       508\n",
      "           1       0.04      0.06      0.05        31\n",
      "\n",
      "    accuracy                           0.85       539\n",
      "   macro avg       0.49      0.48      0.48       539\n",
      "weighted avg       0.89      0.85      0.87       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  87.79582366589327\n",
      "Confusion Matrix: \n",
      " [[1874  178]\n",
      " [  85   18]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      2052\n",
      "           1       0.09      0.17      0.12       103\n",
      "\n",
      "    accuracy                           0.88      2155\n",
      "   macro avg       0.52      0.54      0.53      2155\n",
      "weighted avg       0.92      0.88      0.90      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  30.0556586270872\n",
      "Confusion Matrix: \n",
      " [[140 368]\n",
      " [  9  22]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.28      0.43       508\n",
      "           1       0.06      0.71      0.10        31\n",
      "\n",
      "    accuracy                           0.30       539\n",
      "   macro avg       0.50      0.49      0.27       539\n",
      "weighted avg       0.89      0.30      0.41       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  31.322505800464036\n",
      "Confusion Matrix: \n",
      " [[ 569 1451]\n",
      " [  29  106]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.28      0.43      2020\n",
      "           1       0.07      0.79      0.13       135\n",
      "\n",
      "    accuracy                           0.31      2155\n",
      "   macro avg       0.51      0.53      0.28      2155\n",
      "weighted avg       0.90      0.31      0.42      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  91.4656771799629\n",
      "Confusion Matrix: \n",
      " [[493  43]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       539\n",
      "   macro avg       0.50      0.46      0.48       539\n",
      "weighted avg       0.99      0.91      0.95       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  92.52900232018561\n",
      "Confusion Matrix: \n",
      " [[1993  133]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.93      2155\n",
      "   macro avg       0.50      0.49      0.49      2155\n",
      "weighted avg       0.97      0.93      0.95      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  66.79035250463822\n",
      "Confusion Matrix: \n",
      " [[ 29 174]\n",
      " [  5 331]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.14      0.24       203\n",
      "           1       0.66      0.99      0.79       336\n",
      "\n",
      "    accuracy                           0.67       539\n",
      "   macro avg       0.75      0.56      0.52       539\n",
      "weighted avg       0.73      0.67      0.58       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 67.53246753246754\n",
      "Confusion Matrix: \n",
      " [[ 50 153]\n",
      " [ 22 314]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.25      0.36       203\n",
      "           1       0.67      0.93      0.78       336\n",
      "\n",
      "    accuracy                           0.68       539\n",
      "   macro avg       0.68      0.59      0.57       539\n",
      "weighted avg       0.68      0.68      0.62       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  64.96519721577727\n",
      "Confusion Matrix: \n",
      " [[ 117  748]\n",
      " [   7 1283]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.14      0.24       865\n",
      "           1       0.63      0.99      0.77      1290\n",
      "\n",
      "    accuracy                           0.65      2155\n",
      "   macro avg       0.79      0.56      0.50      2155\n",
      "weighted avg       0.76      0.65      0.56      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 64.5939675174014\n",
      "Confusion Matrix: \n",
      " [[ 186  679]\n",
      " [  84 1206]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.22      0.33       865\n",
      "           1       0.64      0.93      0.76      1290\n",
      "\n",
      "    accuracy                           0.65      2155\n",
      "   macro avg       0.66      0.57      0.54      2155\n",
      "weighted avg       0.66      0.65      0.59      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  85.71428571428571\n",
      "Confusion Matrix: \n",
      " [[460  48]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92       508\n",
      "           1       0.04      0.06      0.05        31\n",
      "\n",
      "    accuracy                           0.86       539\n",
      "   macro avg       0.49      0.49      0.49       539\n",
      "weighted avg       0.89      0.86      0.87       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  88.21345707656613\n",
      "Confusion Matrix: \n",
      " [[1885  167]\n",
      " [  87   16]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      2052\n",
      "           1       0.09      0.16      0.11       103\n",
      "\n",
      "    accuracy                           0.88      2155\n",
      "   macro avg       0.52      0.54      0.52      2155\n",
      "weighted avg       0.91      0.88      0.90      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figurative Accuracy score(train data with multiple features): 95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  39.332096474953616\n",
      "Confusion Matrix: \n",
      " [[191 317]\n",
      " [ 10  21]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.38      0.54       508\n",
      "           1       0.06      0.68      0.11        31\n",
      "\n",
      "    accuracy                           0.39       539\n",
      "   macro avg       0.51      0.53      0.33       539\n",
      "weighted avg       0.90      0.39      0.51       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  40.928074245939676\n",
      "Confusion Matrix: \n",
      " [[ 785 1235]\n",
      " [  38   97]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.39      0.55      2020\n",
      "           1       0.07      0.72      0.13       135\n",
      "\n",
      "    accuracy                           0.41      2155\n",
      "   macro avg       0.51      0.55      0.34      2155\n",
      "weighted avg       0.90      0.41      0.53      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  91.83673469387756\n",
      "Confusion Matrix: \n",
      " [[495  41]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.92       539\n",
      "   macro avg       0.50      0.46      0.48       539\n",
      "weighted avg       0.99      0.92      0.95       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  92.80742459396751\n",
      "Confusion Matrix: \n",
      " [[1999  127]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.93      2155\n",
      "   macro avg       0.50      0.49      0.49      2155\n",
      "weighted avg       0.97      0.93      0.95      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  67.16141001855289\n",
      "Confusion Matrix: \n",
      " [[ 52 151]\n",
      " [ 26 310]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.26      0.37       203\n",
      "           1       0.67      0.92      0.78       336\n",
      "\n",
      "    accuracy                           0.67       539\n",
      "   macro avg       0.67      0.59      0.57       539\n",
      "weighted avg       0.67      0.67      0.62       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 67.3469387755102\n",
      "Confusion Matrix: \n",
      " [[ 53 150]\n",
      " [ 26 310]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.26      0.38       203\n",
      "           1       0.67      0.92      0.78       336\n",
      "\n",
      "    accuracy                           0.67       539\n",
      "   macro avg       0.67      0.59      0.58       539\n",
      "weighted avg       0.67      0.67      0.63       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  64.68677494199537\n",
      "Confusion Matrix: \n",
      " [[ 201  664]\n",
      " [  97 1193]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.23      0.35       865\n",
      "           1       0.64      0.92      0.76      1290\n",
      "\n",
      "    accuracy                           0.65      2155\n",
      "   macro avg       0.66      0.58      0.55      2155\n",
      "weighted avg       0.66      0.65      0.59      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 65.4292343387471\n",
      "Confusion Matrix: \n",
      " [[ 214  651]\n",
      " [  94 1196]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.25      0.36       865\n",
      "           1       0.65      0.93      0.76      1290\n",
      "\n",
      "    accuracy                           0.65      2155\n",
      "   macro avg       0.67      0.59      0.56      2155\n",
      "weighted avg       0.67      0.65      0.60      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  86.45640074211502\n",
      "Confusion Matrix: \n",
      " [[464  44]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93       508\n",
      "           1       0.04      0.06      0.05        31\n",
      "\n",
      "    accuracy                           0.86       539\n",
      "   macro avg       0.49      0.49      0.49       539\n",
      "weighted avg       0.89      0.86      0.88       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  89.6983758700696\n",
      "Confusion Matrix: \n",
      " [[1920  132]\n",
      " [  90   13]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      2052\n",
      "           1       0.09      0.13      0.10       103\n",
      "\n",
      "    accuracy                           0.90      2155\n",
      "   macro avg       0.52      0.53      0.53      2155\n",
      "weighted avg       0.91      0.90      0.91      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  84.60111317254174\n",
      "Confusion Matrix: \n",
      " [[456  52]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.85       539\n",
      "   macro avg       0.47      0.45      0.46       539\n",
      "weighted avg       0.88      0.85      0.86       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  90.44083526682135\n",
      "Confusion Matrix: \n",
      " [[1931   89]\n",
      " [ 117   18]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      2020\n",
      "           1       0.17      0.13      0.15       135\n",
      "\n",
      "    accuracy                           0.90      2155\n",
      "   macro avg       0.56      0.54      0.55      2155\n",
      "weighted avg       0.89      0.90      0.90      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  95.17625231910947\n",
      "Confusion Matrix: \n",
      " [[513  23]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.95       539\n",
      "   macro avg       0.50      0.48      0.49       539\n",
      "weighted avg       0.99      0.95      0.97       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  94.66357308584686\n",
      "Confusion Matrix: \n",
      " [[2039   87]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      2126\n",
      "           1       0.01      0.03      0.02        29\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.50      0.50      0.49      2155\n",
      "weighted avg       0.97      0.95      0.96      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  67.16141001855289\n",
      "Confusion Matrix: \n",
      " [[ 63 140]\n",
      " [ 37 299]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.31      0.42       203\n",
      "           1       0.68      0.89      0.77       336\n",
      "\n",
      "    accuracy                           0.67       539\n",
      "   macro avg       0.66      0.60      0.59       539\n",
      "weighted avg       0.66      0.67      0.64       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 66.97588126159555\n",
      "Confusion Matrix: \n",
      " [[ 54 149]\n",
      " [ 29 307]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.27      0.38       203\n",
      "           1       0.67      0.91      0.78       336\n",
      "\n",
      "    accuracy                           0.67       539\n",
      "   macro avg       0.66      0.59      0.58       539\n",
      "weighted avg       0.66      0.67      0.63       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  69.32714617169373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[ 328  537]\n",
      " [ 124 1166]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.38      0.50       865\n",
      "           1       0.68      0.90      0.78      1290\n",
      "\n",
      "    accuracy                           0.69      2155\n",
      "   macro avg       0.71      0.64      0.64      2155\n",
      "weighted avg       0.70      0.69      0.67      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 67.05336426914154\n",
      "Confusion Matrix: \n",
      " [[ 256  609]\n",
      " [ 101 1189]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.30      0.42       865\n",
      "           1       0.66      0.92      0.77      1290\n",
      "\n",
      "    accuracy                           0.67      2155\n",
      "   macro avg       0.69      0.61      0.59      2155\n",
      "weighted avg       0.68      0.67      0.63      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  74.76808905380335\n",
      "Confusion Matrix: \n",
      " [[111  92]\n",
      " [ 44 292]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.55      0.62       203\n",
      "           1       0.76      0.87      0.81       336\n",
      "\n",
      "    accuracy                           0.75       539\n",
      "   macro avg       0.74      0.71      0.72       539\n",
      "weighted avg       0.74      0.75      0.74       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 67.71799628942486\n",
      "Confusion Matrix: \n",
      " [[ 62 141]\n",
      " [ 33 303]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.31      0.42       203\n",
      "           1       0.68      0.90      0.78       336\n",
      "\n",
      "    accuracy                           0.68       539\n",
      "   macro avg       0.67      0.60      0.60       539\n",
      "weighted avg       0.67      0.68      0.64       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  80.83526682134571\n",
      "Confusion Matrix: \n",
      " [[ 607  258]\n",
      " [ 155 1135]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.75       865\n",
      "           1       0.81      0.88      0.85      1290\n",
      "\n",
      "    accuracy                           0.81      2155\n",
      "   macro avg       0.81      0.79      0.80      2155\n",
      "weighted avg       0.81      0.81      0.81      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 69.51276102088167\n",
      "Confusion Matrix: \n",
      " [[ 318  547]\n",
      " [ 110 1180]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.37      0.49       865\n",
      "           1       0.68      0.91      0.78      1290\n",
      "\n",
      "    accuracy                           0.70      2155\n",
      "   macro avg       0.71      0.64      0.64      2155\n",
      "weighted avg       0.71      0.70      0.67      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dirty Accuracy score(test data with multiple features): 99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  81.63265306122449\n",
      "Confusion Matrix: \n",
      " [[183  20]\n",
      " [ 79 257]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.90      0.79       203\n",
      "           1       0.93      0.76      0.84       336\n",
      "\n",
      "    accuracy                           0.82       539\n",
      "   macro avg       0.81      0.83      0.81       539\n",
      "weighted avg       0.84      0.82      0.82       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 71.61410018552876\n",
      "Confusion Matrix: \n",
      " [[ 89 114]\n",
      " [ 39 297]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.44      0.54       203\n",
      "           1       0.72      0.88      0.80       336\n",
      "\n",
      "    accuracy                           0.72       539\n",
      "   macro avg       0.71      0.66      0.67       539\n",
      "weighted avg       0.71      0.72      0.70       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  86.49651972157773\n",
      "Confusion Matrix: \n",
      " [[ 816   49]\n",
      " [ 242 1048]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85       865\n",
      "           1       0.96      0.81      0.88      1290\n",
      "\n",
      "    accuracy                           0.86      2155\n",
      "   macro avg       0.86      0.88      0.86      2155\n",
      "weighted avg       0.88      0.86      0.87      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 72.25058004640371\n",
      "Confusion Matrix: \n",
      " [[ 396  469]\n",
      " [ 129 1161]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.46      0.57       865\n",
      "           1       0.71      0.90      0.80      1290\n",
      "\n",
      "    accuracy                           0.72      2155\n",
      "   macro avg       0.73      0.68      0.68      2155\n",
      "weighted avg       0.73      0.72      0.70      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  57.5139146567718\n",
      "Confusion Matrix: \n",
      " [[201   2]\n",
      " [227 109]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.99      0.64       203\n",
      "           1       0.98      0.32      0.49       336\n",
      "\n",
      "    accuracy                           0.58       539\n",
      "   macro avg       0.73      0.66      0.56       539\n",
      "weighted avg       0.79      0.58      0.54       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 74.39703153988869\n",
      "Confusion Matrix: \n",
      " [[118  85]\n",
      " [ 53 283]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.58      0.63       203\n",
      "           1       0.77      0.84      0.80       336\n",
      "\n",
      "    accuracy                           0.74       539\n",
      "   macro avg       0.73      0.71      0.72       539\n",
      "weighted avg       0.74      0.74      0.74       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  68.49187935034803\n",
      "Confusion Matrix: \n",
      " [[864   1]\n",
      " [678 612]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.72       865\n",
      "           1       1.00      0.47      0.64      1290\n",
      "\n",
      "    accuracy                           0.68      2155\n",
      "   macro avg       0.78      0.74      0.68      2155\n",
      "weighted avg       0.82      0.68      0.67      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 79.62877030162413\n",
      "Confusion Matrix: \n",
      " [[ 603  262]\n",
      " [ 177 1113]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73       865\n",
      "           1       0.81      0.86      0.84      1290\n",
      "\n",
      "    accuracy                           0.80      2155\n",
      "   macro avg       0.79      0.78      0.78      2155\n",
      "weighted avg       0.79      0.80      0.79      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  37.66233766233766\n",
      "Confusion Matrix: \n",
      " [[203   0]\n",
      " [336   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      1.00      0.55       203\n",
      "           1       0.00      0.00      0.00       336\n",
      "\n",
      "    accuracy                           0.38       539\n",
      "   macro avg       0.19      0.50      0.27       539\n",
      "weighted avg       0.14      0.38      0.21       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(test data with multiple features): 37.66233766233766\n",
      "Confusion Matrix: \n",
      " [[203   0]\n",
      " [336   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      1.00      0.55       203\n",
      "           1       0.00      0.00      0.00       336\n",
      "\n",
      "    accuracy                           0.38       539\n",
      "   macro avg       0.19      0.50      0.27       539\n",
      "weighted avg       0.14      0.38      0.21       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  40.13921113689095\n",
      "Confusion Matrix: \n",
      " [[ 865    0]\n",
      " [1290    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      1.00      0.57       865\n",
      "           1       0.00      0.00      0.00      1290\n",
      "\n",
      "    accuracy                           0.40      2155\n",
      "   macro avg       0.20      0.50      0.29      2155\n",
      "weighted avg       0.16      0.40      0.23      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with multiple features): 40.13921113689095\n",
      "Confusion Matrix: \n",
      " [[ 865    0]\n",
      " [1290    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      1.00      0.57       865\n",
      "           1       0.00      0.00      0.00      1290\n",
      "\n",
      "    accuracy                           0.40      2155\n",
      "   macro avg       0.20      0.50      0.29      2155\n",
      "weighted avg       0.16      0.40      0.23      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with multiple features): 95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(test data with multiple features): 94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with multiple features): 93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(test data with multiple features): 99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with multiple features): 98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Naive bays\n",
    "import numpy\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#ensemble model of comments feature and context feature\n",
    "abusive_type = [\"Rude\",\"Figurative\",\"Offensive\",\"Dirty\"]\n",
    "report=[]\n",
    "header = 0;\n",
    "for threshold in numpy.arange(0.1,1.1,0.1):\n",
    "    for i in range(0,4):\n",
    "        Naive_bayes_1 = MultinomialNB()\n",
    "        Naive_bayes_2 = MultinomialNB()\n",
    "\n",
    "        Naive_bayes_1.fit(Train_X_Tfidf, Train_Y[abusive_type[i]])\n",
    "        Naive_bayes_2.fit(train_feat_context, Train_Y[abusive_type[i]])\n",
    "\n",
    "        predictions_NB_Train1 = Naive_bayes_1.predict_proba(Train_X_Tfidf)\n",
    "        predictions_NB_Train2 = Naive_bayes_2.predict_proba(train_feat_context)\n",
    "\n",
    "        predictions_NB_Test1 = Naive_bayes_1.predict_proba(Test_X_Tfidf)\n",
    "        predictions_NB_Test2 = Naive_bayes_2.predict_proba(test_feat_context)\n",
    "\n",
    "        predictions_NB_Train = (predictions_NB_Train1+predictions_NB_Train2)/2\n",
    "        predictions_NB_Test = (predictions_NB_Test1+predictions_NB_Test2)/2\n",
    "\n",
    "        predictions_class_Train = predict_class(predictions_NB_Train,threshold)\n",
    "        predictions_class_Test = predict_class(predictions_NB_Test,threshold)\n",
    "\n",
    "        #combine multiple feature with one model\n",
    "        Naive_bayes_3 = MultinomialNB()\n",
    "        Naive_bayes_3.fit(train_feat, Train_Y[abusive_type[i]])\n",
    "        predictions_NB_Train3 = Naive_bayes_3.predict_proba(train_feat)\n",
    "        predictions_NB_Test3 = Naive_bayes_3.predict_proba(test_feat)\n",
    "\n",
    "        predictions_class_Train_c = (predictions_NB_Train3 [:,1] >= threshold).astype('int')\n",
    "        predictions_class_Test_c = (predictions_NB_Test3 [:,1] >= threshold).astype('int')\n",
    "    #     predictions_class_Train_c = Naive_bayes_3.predict(train_feat)\n",
    "    #     predictions_class_Test_c = Naive_bayes_3.predict(test_feat)\n",
    "        report_performance(predictions_class_Train, predictions_class_Test, predictions_class_Train_c,predictions_class_Test_c, abusive_type[i],threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  64.19294990723562\n",
      "Confusion Matrix: \n",
      " [[ 25 178]\n",
      " [ 15 321]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.12      0.21       203\n",
      "           1       0.64      0.96      0.77       336\n",
      "\n",
      "    accuracy                           0.64       539\n",
      "   macro avg       0.63      0.54      0.49       539\n",
      "weighted avg       0.64      0.64      0.56       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  60.278422273781906\n",
      "Confusion Matrix: \n",
      " [[  72  793]\n",
      " [  63 1227]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.08      0.14       865\n",
      "           1       0.61      0.95      0.74      1290\n",
      "\n",
      "    accuracy                           0.60      2155\n",
      "   macro avg       0.57      0.52      0.44      2155\n",
      "weighted avg       0.58      0.60      0.50      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  82.74582560296847\n",
      "Confusion Matrix: \n",
      " [[444  64]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91       508\n",
      "           1       0.03      0.06      0.04        31\n",
      "\n",
      "    accuracy                           0.83       539\n",
      "   macro avg       0.48      0.47      0.47       539\n",
      "weighted avg       0.89      0.83      0.86       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  85.47563805104407\n",
      "Confusion Matrix: \n",
      " [[1819  233]\n",
      " [  80   23]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      2052\n",
      "           1       0.09      0.22      0.13       103\n",
      "\n",
      "    accuracy                           0.85      2155\n",
      "   macro avg       0.52      0.55      0.52      2155\n",
      "weighted avg       0.92      0.85      0.88      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  23.00556586270872\n",
      "Confusion Matrix: \n",
      " [[ 98 410]\n",
      " [  5  26]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.19      0.32       508\n",
      "           1       0.06      0.84      0.11        31\n",
      "\n",
      "    accuracy                           0.23       539\n",
      "   macro avg       0.51      0.52      0.22       539\n",
      "weighted avg       0.90      0.23      0.31       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  21.856148491879352\n",
      "Confusion Matrix: \n",
      " [[ 357 1663]\n",
      " [  21  114]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.18      0.30      2020\n",
      "           1       0.06      0.84      0.12       135\n",
      "\n",
      "    accuracy                           0.22      2155\n",
      "   macro avg       0.50      0.51      0.21      2155\n",
      "weighted avg       0.89      0.22      0.29      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  89.98144712430427\n",
      "Confusion Matrix: \n",
      " [[485  51]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.95       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.90       539\n",
      "   macro avg       0.50      0.45      0.47       539\n",
      "weighted avg       0.99      0.90      0.94       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  90.8584686774942\n",
      "Confusion Matrix: \n",
      " [[1956  170]\n",
      " [  27    2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      2126\n",
      "           1       0.01      0.07      0.02        29\n",
      "\n",
      "    accuracy                           0.91      2155\n",
      "   macro avg       0.50      0.49      0.49      2155\n",
      "weighted avg       0.97      0.91      0.94      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  63.63636363636363\n",
      "Confusion Matrix: \n",
      " [[ 25 178]\n",
      " [ 18 318]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.12      0.20       203\n",
      "           1       0.64      0.95      0.76       336\n",
      "\n",
      "    accuracy                           0.64       539\n",
      "   macro avg       0.61      0.53      0.48       539\n",
      "weighted avg       0.62      0.64      0.55       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  60.23201856148492\n",
      "Confusion Matrix: \n",
      " [[  78  787]\n",
      " [  70 1220]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.09      0.15       865\n",
      "           1       0.61      0.95      0.74      1290\n",
      "\n",
      "    accuracy                           0.60      2155\n",
      "   macro avg       0.57      0.52      0.45      2155\n",
      "weighted avg       0.58      0.60      0.50      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  83.85899814471243\n",
      "Confusion Matrix: \n",
      " [[450  58]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       508\n",
      "           1       0.03      0.06      0.04        31\n",
      "\n",
      "    accuracy                           0.84       539\n",
      "   macro avg       0.49      0.48      0.48       539\n",
      "weighted avg       0.89      0.84      0.86       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  86.58932714617168\n",
      "Confusion Matrix: \n",
      " [[1846  206]\n",
      " [  83   20]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      2052\n",
      "           1       0.09      0.19      0.12       103\n",
      "\n",
      "    accuracy                           0.87      2155\n",
      "   macro avg       0.52      0.55      0.52      2155\n",
      "weighted avg       0.92      0.87      0.89      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  24.489795918367346\n",
      "Confusion Matrix: \n",
      " [[107 401]\n",
      " [  6  25]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.21      0.34       508\n",
      "           1       0.06      0.81      0.11        31\n",
      "\n",
      "    accuracy                           0.24       539\n",
      "   macro avg       0.50      0.51      0.23       539\n",
      "weighted avg       0.90      0.24      0.33       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  24.872389791183295\n",
      "Confusion Matrix: \n",
      " [[ 425 1595]\n",
      " [  24  111]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.21      0.34      2020\n",
      "           1       0.07      0.82      0.12       135\n",
      "\n",
      "    accuracy                           0.25      2155\n",
      "   macro avg       0.51      0.52      0.23      2155\n",
      "weighted avg       0.89      0.25      0.33      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  91.28014842300557\n",
      "Confusion Matrix: \n",
      " [[492  44]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       539\n",
      "   macro avg       0.50      0.46      0.48       539\n",
      "weighted avg       0.99      0.91      0.95       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  91.46171693735499\n",
      "Confusion Matrix: \n",
      " [[1970  156]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.91      2155\n",
      "   macro avg       0.50      0.48      0.48      2155\n",
      "weighted avg       0.97      0.91      0.94      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  64.0074211502783\n",
      "Confusion Matrix: \n",
      " [[ 27 176]\n",
      " [ 18 318]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.13      0.22       203\n",
      "           1       0.64      0.95      0.77       336\n",
      "\n",
      "    accuracy                           0.64       539\n",
      "   macro avg       0.62      0.54      0.49       539\n",
      "weighted avg       0.63      0.64      0.56       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  60.278422273781906\n",
      "Confusion Matrix: \n",
      " [[  86  779]\n",
      " [  77 1213]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.10      0.17       865\n",
      "           1       0.61      0.94      0.74      1290\n",
      "\n",
      "    accuracy                           0.60      2155\n",
      "   macro avg       0.57      0.52      0.45      2155\n",
      "weighted avg       0.58      0.60      0.51      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  84.60111317254174\n",
      "Confusion Matrix: \n",
      " [[454  54]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92       508\n",
      "           1       0.04      0.06      0.05        31\n",
      "\n",
      "    accuracy                           0.85       539\n",
      "   macro avg       0.49      0.48      0.48       539\n",
      "weighted avg       0.89      0.85      0.87       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  87.33178654292342\n",
      "Confusion Matrix: \n",
      " [[1864  188]\n",
      " [  85   18]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      2052\n",
      "           1       0.09      0.17      0.12       103\n",
      "\n",
      "    accuracy                           0.87      2155\n",
      "   macro avg       0.52      0.54      0.52      2155\n",
      "weighted avg       0.91      0.87      0.89      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  26.716141001855288\n",
      "Confusion Matrix: \n",
      " [[120 388]\n",
      " [  7  24]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.24      0.38       508\n",
      "           1       0.06      0.77      0.11        31\n",
      "\n",
      "    accuracy                           0.27       539\n",
      "   macro avg       0.50      0.51      0.24       539\n",
      "weighted avg       0.89      0.27      0.36       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  27.00696055684455\n",
      "Confusion Matrix: \n",
      " [[ 473 1547]\n",
      " [  26  109]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.23      0.38      2020\n",
      "           1       0.07      0.81      0.12       135\n",
      "\n",
      "    accuracy                           0.27      2155\n",
      "   macro avg       0.51      0.52      0.25      2155\n",
      "weighted avg       0.89      0.27      0.36      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  91.4656771799629\n",
      "Confusion Matrix: \n",
      " [[493  43]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       539\n",
      "   macro avg       0.50      0.46      0.48       539\n",
      "weighted avg       0.99      0.91      0.95       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  92.15777262180974\n",
      "Confusion Matrix: \n",
      " [[1985  141]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.92      2155\n",
      "   macro avg       0.50      0.48      0.49      2155\n",
      "weighted avg       0.97      0.92      0.95      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  64.19294990723562\n",
      "Confusion Matrix: \n",
      " [[ 33 170]\n",
      " [ 23 313]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.16      0.25       203\n",
      "           1       0.65      0.93      0.76       336\n",
      "\n",
      "    accuracy                           0.64       539\n",
      "   macro avg       0.62      0.55      0.51       539\n",
      "weighted avg       0.63      0.64      0.57       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  60.928074245939676\n",
      "Confusion Matrix: \n",
      " [[ 110  755]\n",
      " [  87 1203]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.13      0.21       865\n",
      "           1       0.61      0.93      0.74      1290\n",
      "\n",
      "    accuracy                           0.61      2155\n",
      "   macro avg       0.59      0.53      0.47      2155\n",
      "weighted avg       0.59      0.61      0.53      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  84.97217068645641\n",
      "Confusion Matrix: \n",
      " [[456  52]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       508\n",
      "           1       0.04      0.06      0.05        31\n",
      "\n",
      "    accuracy                           0.85       539\n",
      "   macro avg       0.49      0.48      0.48       539\n",
      "weighted avg       0.89      0.85      0.87       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  87.88863109048724\n",
      "Confusion Matrix: \n",
      " [[1877  175]\n",
      " [  86   17]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      2052\n",
      "           1       0.09      0.17      0.12       103\n",
      "\n",
      "    accuracy                           0.88      2155\n",
      "   macro avg       0.52      0.54      0.53      2155\n",
      "weighted avg       0.91      0.88      0.90      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  32.467532467532465\n",
      "Confusion Matrix: \n",
      " [[154 354]\n",
      " [ 10  21]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.30      0.46       508\n",
      "           1       0.06      0.68      0.10        31\n",
      "\n",
      "    accuracy                           0.32       539\n",
      "   macro avg       0.50      0.49      0.28       539\n",
      "weighted avg       0.89      0.32      0.44       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  33.874709976798144\n",
      "Confusion Matrix: \n",
      " [[ 625 1395]\n",
      " [  30  105]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.31      0.47      2020\n",
      "           1       0.07      0.78      0.13       135\n",
      "\n",
      "    accuracy                           0.34      2155\n",
      "   macro avg       0.51      0.54      0.30      2155\n",
      "weighted avg       0.90      0.34      0.45      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  91.65120593692022\n",
      "Confusion Matrix: \n",
      " [[494  42]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.92       539\n",
      "   macro avg       0.50      0.46      0.48       539\n",
      "weighted avg       0.99      0.92      0.95       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  92.5754060324826\n",
      "Confusion Matrix: \n",
      " [[1994  132]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      2126\n",
      "           1       0.01      0.03      0.01        29\n",
      "\n",
      "    accuracy                           0.93      2155\n",
      "   macro avg       0.50      0.49      0.49      2155\n",
      "weighted avg       0.97      0.93      0.95      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  67.16141001855289\n",
      "Confusion Matrix: \n",
      " [[ 52 151]\n",
      " [ 26 310]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.26      0.37       203\n",
      "           1       0.67      0.92      0.78       336\n",
      "\n",
      "    accuracy                           0.67       539\n",
      "   macro avg       0.67      0.59      0.57       539\n",
      "weighted avg       0.67      0.67      0.62       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  64.68677494199537\n",
      "Confusion Matrix: \n",
      " [[ 201  664]\n",
      " [  97 1193]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.23      0.35       865\n",
      "           1       0.64      0.92      0.76      1290\n",
      "\n",
      "    accuracy                           0.65      2155\n",
      "   macro avg       0.66      0.58      0.55      2155\n",
      "weighted avg       0.66      0.65      0.59      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  86.45640074211502\n",
      "Confusion Matrix: \n",
      " [[464  44]\n",
      " [ 29   2]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93       508\n",
      "           1       0.04      0.06      0.05        31\n",
      "\n",
      "    accuracy                           0.86       539\n",
      "   macro avg       0.49      0.49      0.49       539\n",
      "weighted avg       0.89      0.86      0.88       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  89.6983758700696\n",
      "Confusion Matrix: \n",
      " [[1920  132]\n",
      " [  90   13]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      2052\n",
      "           1       0.09      0.13      0.10       103\n",
      "\n",
      "    accuracy                           0.90      2155\n",
      "   macro avg       0.52      0.53      0.53      2155\n",
      "weighted avg       0.91      0.90      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  84.60111317254174\n",
      "Confusion Matrix: \n",
      " [[456  52]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.85       539\n",
      "   macro avg       0.47      0.45      0.46       539\n",
      "weighted avg       0.88      0.85      0.86       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  90.44083526682135\n",
      "Confusion Matrix: \n",
      " [[1931   89]\n",
      " [ 117   18]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      2020\n",
      "           1       0.17      0.13      0.15       135\n",
      "\n",
      "    accuracy                           0.90      2155\n",
      "   macro avg       0.56      0.54      0.55      2155\n",
      "weighted avg       0.89      0.90      0.90      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  95.17625231910947\n",
      "Confusion Matrix: \n",
      " [[513  23]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.95       539\n",
      "   macro avg       0.50      0.48      0.49       539\n",
      "weighted avg       0.99      0.95      0.97       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  94.66357308584686\n",
      "Confusion Matrix: \n",
      " [[2039   87]\n",
      " [  28    1]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      2126\n",
      "           1       0.01      0.03      0.02        29\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.50      0.50      0.49      2155\n",
      "weighted avg       0.97      0.95      0.96      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  70.50092764378478\n",
      "Confusion Matrix: \n",
      " [[ 75 128]\n",
      " [ 31 305]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.37      0.49       203\n",
      "           1       0.70      0.91      0.79       336\n",
      "\n",
      "    accuracy                           0.71       539\n",
      "   macro avg       0.71      0.64      0.64       539\n",
      "weighted avg       0.71      0.71      0.68       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  75.54524361948955\n",
      "Confusion Matrix: \n",
      " [[ 445  420]\n",
      " [ 107 1183]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.51      0.63       865\n",
      "           1       0.74      0.92      0.82      1290\n",
      "\n",
      "    accuracy                           0.76      2155\n",
      "   macro avg       0.77      0.72      0.72      2155\n",
      "weighted avg       0.77      0.76      0.74      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  83.6734693877551\n",
      "Confusion Matrix: \n",
      " [[156  47]\n",
      " [ 41 295]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78       203\n",
      "           1       0.86      0.88      0.87       336\n",
      "\n",
      "    accuracy                           0.84       539\n",
      "   macro avg       0.83      0.82      0.83       539\n",
      "weighted avg       0.84      0.84      0.84       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  88.39907192575406\n",
      "Confusion Matrix: \n",
      " [[ 737  128]\n",
      " [ 122 1168]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85       865\n",
      "           1       0.90      0.91      0.90      1290\n",
      "\n",
      "    accuracy                           0.88      2155\n",
      "   macro avg       0.88      0.88      0.88      2155\n",
      "weighted avg       0.88      0.88      0.88      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  79.96289424860854\n",
      "Confusion Matrix: \n",
      " [[194   9]\n",
      " [ 99 237]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.96      0.78       203\n",
      "           1       0.96      0.71      0.81       336\n",
      "\n",
      "    accuracy                           0.80       539\n",
      "   macro avg       0.81      0.83      0.80       539\n",
      "weighted avg       0.85      0.80      0.80       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  89.88399071925754\n",
      "Confusion Matrix: \n",
      " [[ 852   13]\n",
      " [ 205 1085]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89       865\n",
      "           1       0.99      0.84      0.91      1290\n",
      "\n",
      "    accuracy                           0.90      2155\n",
      "   macro avg       0.90      0.91      0.90      2155\n",
      "weighted avg       0.92      0.90      0.90      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  56.029684601113175\n",
      "Confusion Matrix: \n",
      " [[203   0]\n",
      " [237  99]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      1.00      0.63       203\n",
      "           1       1.00      0.29      0.46       336\n",
      "\n",
      "    accuracy                           0.56       539\n",
      "   macro avg       0.73      0.65      0.54       539\n",
      "weighted avg       0.80      0.56      0.52       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  68.44547563805105\n",
      "Confusion Matrix: \n",
      " [[864   1]\n",
      " [679 611]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.72       865\n",
      "           1       1.00      0.47      0.64      1290\n",
      "\n",
      "    accuracy                           0.68      2155\n",
      "   macro avg       0.78      0.74      0.68      2155\n",
      "weighted avg       0.82      0.68      0.67      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Rude Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  37.66233766233766\n",
      "Confusion Matrix: \n",
      " [[203   0]\n",
      " [336   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      1.00      0.55       203\n",
      "           1       0.00      0.00      0.00       336\n",
      "\n",
      "    accuracy                           0.38       539\n",
      "   macro avg       0.19      0.50      0.27       539\n",
      "weighted avg       0.14      0.38      0.21       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Rude Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  40.13921113689095\n",
      "Confusion Matrix: \n",
      " [[ 865    0]\n",
      " [1290    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      1.00      0.57       865\n",
      "           1       0.00      0.00      0.00      1290\n",
      "\n",
      "    accuracy                           0.40      2155\n",
      "   macro avg       0.20      0.50      0.29      2155\n",
      "weighted avg       0.16      0.40      0.23      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Figurative Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Figurative Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  95.22041763341068\n",
      "Confusion Matrix: \n",
      " [[2052    0]\n",
      " [ 103    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      2052\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.95      2155\n",
      "   macro avg       0.48      0.50      0.49      2155\n",
      "weighted avg       0.91      0.95      0.93      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offensive Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  94.24860853432281\n",
      "Confusion Matrix: \n",
      " [[508   0]\n",
      " [ 31   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       508\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.94       539\n",
      "   macro avg       0.47      0.50      0.49       539\n",
      "weighted avg       0.89      0.94      0.91       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Offensive Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  93.7354988399072\n",
      "Confusion Matrix: \n",
      " [[2020    0]\n",
      " [ 135    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      2020\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.94      2155\n",
      "   macro avg       0.47      0.50      0.48      2155\n",
      "weighted avg       0.88      0.94      0.91      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n",
      "Dirty Accuracy score(test data with ensemble (1 model: content feature, 1 model: context feature):  99.44341372912801\n",
      "Confusion Matrix: \n",
      " [[536   0]\n",
      " [  3   0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       536\n",
      "           1       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       539\n",
      "   macro avg       0.50      0.50      0.50       539\n",
      "weighted avg       0.99      0.99      0.99       539\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Dirty Accuracy score(train data with ensemble (1 model: content feature, 1 model: context feature):  98.65429234338747\n",
      "Confusion Matrix: \n",
      " [[2126    0]\n",
      " [  29    0]]\n",
      "PRF: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2126\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      2155\n",
      "   macro avg       0.49      0.50      0.50      2155\n",
      "weighted avg       0.97      0.99      0.98      2155\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/posoma/miniconda3/envs/posoma/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Naive bays\n",
    "import numpy\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#P=threshold*(content)+(1-threshold)*(context)\n",
    "#ensemble model of comments feature and context feature\n",
    "abusive_type = [\"Rude\",\"Figurative\",\"Offensive\",\"Dirty\"]\n",
    "report=[]\n",
    "for threshold in numpy.arange(0.1,1.1,0.1):\n",
    "    for i in range(0,4):\n",
    "        Naive_bayes_1 = MultinomialNB()\n",
    "        Naive_bayes_2 = MultinomialNB()\n",
    "\n",
    "        Naive_bayes_1.fit(Train_X_Tfidf, Train_Y[abusive_type[i]])\n",
    "        Naive_bayes_2.fit(train_feat_context, Train_Y[abusive_type[i]])\n",
    "\n",
    "        predictions_NB_Train1 = Naive_bayes_1.predict_proba(Train_X_Tfidf)\n",
    "        predictions_NB_Train2 = Naive_bayes_2.predict_proba(train_feat_context)\n",
    "\n",
    "        predictions_NB_Test1 = Naive_bayes_1.predict_proba(Test_X_Tfidf)\n",
    "        predictions_NB_Test2 = Naive_bayes_2.predict_proba(test_feat_context)\n",
    "\n",
    "        predictions_NB_Train = (predictions_NB_Train1*threshold)+(predictions_NB_Train2*(1-threshold))\n",
    "        predictions_NB_Test = (predictions_NB_Test1*threshold)+(predictions_NB_Test2*(1-threshold))\n",
    "\n",
    "        predictions_class_Train = predict_class(predictions_NB_Train,threshold)\n",
    "        predictions_class_Test = predict_class(predictions_NB_Test,threshold)\n",
    "\n",
    "        report_performance_threshold_1_minus_threshold(predictions_class_Train, predictions_class_Test, abusive_type[i],threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-3c45d7477ced>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'comment'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Rude'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions_NB_Rude_Train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Figurative'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions_NB_Figurative_Train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Offensive'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions_NB_Offensive_Train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Dirty'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions_NB_Dirty_Train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/posoma/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_frame'"
     ]
    }
   ],
   "source": [
    "a = Train_X.to_frame(name='comment')\n",
    "a['Rude'] = predictions_NB_Rude_Train[:,1]\n",
    "a['Figurative'] = predictions_NB_Figurative_Train[:,1]\n",
    "a['Offensive'] = predictions_NB_Offensive_Train[:,1]\n",
    "a['Dirty'] = predictions_NB_Dirty_Train[:,1]\n",
    "a.to_csv('nb-tfidf-predict_train.csv')\n",
    "\n",
    "b = Test_X.to_frame(name='comment')\n",
    "b['Rude'] = predictions_NB_Rude_Test[:,1]\n",
    "b['Figurative'] = predictions_NB_Figurative_Test[:,1]\n",
    "b['Offensive'] = predictions_NB_Offensive_Test[:,1]\n",
    "b['Dirty'] = predictions_NB_Dirty_Test[:,1]\n",
    "b.to_csv('nb-tfidf-predict_test.csv')\n",
    "\n",
    "c = Train_X.to_frame(name='comment')\n",
    "c['Rude'] = Train_Y['Rude']\n",
    "c['Figurative'] = Train_Y['Figurative']\n",
    "c['Offensive'] = Train_Y['Offensive']\n",
    "c['Dirty'] = Train_Y['Dirty']\n",
    "c.to_csv('train_and_label.csv')\n",
    "\n",
    "d = Test_X.to_frame(name='comment')\n",
    "d['Rude'] = Test_Y['Rude']\n",
    "d['Figurative'] = Test_Y['Figurative']\n",
    "d['Offensive'] = Test_Y['Offensive']\n",
    "d['Dirty'] = Test_Y['Dirty']\n",
    "d.to_csv('test_and_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>reaction1</th>\n",
       "      <th>reaction2</th>\n",
       "      <th>reaction3</th>\n",
       "      <th>reaction_num</th>\n",
       "      <th>reply_num</th>\n",
       "      <th>comment_time</th>\n",
       "      <th>type1</th>\n",
       "      <th>type2</th>\n",
       "      <th>Rude</th>\n",
       "      <th>Figurative</th>\n",
       "      <th>Offensive</th>\n",
       "      <th>Dirty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>อย่างที่กูบอกเป๊ะ แม่งยื้อ ออกข่าวว่ากำลังรับผ...</td>\n",
       "      <td>10157700000000000</td>\n",
       "      <td>like</td>\n",
       "      <td>sad</td>\n",
       "      <td>angry</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>43681.89306</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>แพรวามึงเกิดมาทำเหี้ยอะไรวะกูถามจริง เกิดมาเป็...</td>\n",
       "      <td>10157700000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>43681.89028</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>รอเรื่องเงียบ มีข่าวอื่นมากลบ ก็ดื้อต่อไปไม่จ่...</td>\n",
       "      <td>10157700000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>43681.89306</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ให้กรมที่ดินมาประเมินกุว่าไม่ถึง50 ล้าน ตั้งรา...</td>\n",
       "      <td>10157700000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>43681.89306</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>คนบ้าๆไร้ค่าคนเดียวทำอีกหลายครอบครัวเค้าเดือดร...</td>\n",
       "      <td>10157700000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>43681.89514</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>สวยๆแบบกุยังไม่กล้าหลอกใครเลย มีโดนเขาหลอก แถม...</td>\n",
       "      <td>10157700000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43670.91528</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>ไม่น่ารับแจ้งความเคสแบบนี้ มึงจะมีเงินเยอะแจกค...</td>\n",
       "      <td>10157700000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43671.41319</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>What 2 ล้านขอกูได้เป็นเมียเป็นตัวเป็นตนได้เลยน...</td>\n",
       "      <td>10157700000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>43670.91736</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>ไม่ได้แดกผมหรอกคัฟ เพราะผมก็ไม่มีจะแดก ๕๕</td>\n",
       "      <td>10157700000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>43670.91597</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>รสชาดใบปอมันจะขมๆ​ แต่มึงดันเจอใบข่อย​ แสบอิ๊บ...</td>\n",
       "      <td>10157700000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43670.92222</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comments         comment_id  \\\n",
       "0    อย่างที่กูบอกเป๊ะ แม่งยื้อ ออกข่าวว่ากำลังรับผ...  10157700000000000   \n",
       "1    แพรวามึงเกิดมาทำเหี้ยอะไรวะกูถามจริง เกิดมาเป็...  10157700000000000   \n",
       "2    รอเรื่องเงียบ มีข่าวอื่นมากลบ ก็ดื้อต่อไปไม่จ่...  10157700000000000   \n",
       "3    ให้กรมที่ดินมาประเมินกุว่าไม่ถึง50 ล้าน ตั้งรา...  10157700000000000   \n",
       "4    คนบ้าๆไร้ค่าคนเดียวทำอีกหลายครอบครัวเค้าเดือดร...  10157700000000000   \n",
       "..                                                 ...                ...   \n",
       "457  สวยๆแบบกุยังไม่กล้าหลอกใครเลย มีโดนเขาหลอก แถม...  10157700000000000   \n",
       "458  ไม่น่ารับแจ้งความเคสแบบนี้ มึงจะมีเงินเยอะแจกค...  10157700000000000   \n",
       "459  What 2 ล้านขอกูได้เป็นเมียเป็นตัวเป็นตนได้เลยน...  10157700000000000   \n",
       "460          ไม่ได้แดกผมหรอกคัฟ เพราะผมก็ไม่มีจะแดก ๕๕  10157700000000000   \n",
       "461  รสชาดใบปอมันจะขมๆ​ แต่มึงดันเจอใบข่อย​ แสบอิ๊บ...  10157700000000000   \n",
       "\n",
       "    reaction1 reaction2 reaction3  reaction_num  reply_num  comment_time  \\\n",
       "0        like       sad     angry           148          0   43681.89306   \n",
       "1         NaN       NaN       NaN            42          2   43681.89028   \n",
       "2         NaN       NaN       NaN             8          0   43681.89306   \n",
       "3         NaN       NaN       NaN            10          1   43681.89306   \n",
       "4         NaN       NaN       NaN             3          0   43681.89514   \n",
       "..        ...       ...       ...           ...        ...           ...   \n",
       "457       NaN       NaN       NaN             1          0   43670.91528   \n",
       "458       NaN       NaN       NaN             1          0   43671.41319   \n",
       "459       NaN       NaN       NaN             4          5   43670.91736   \n",
       "460       NaN       NaN       NaN             3          0   43670.91597   \n",
       "461       NaN       NaN       NaN             1          0   43670.92222   \n",
       "\n",
       "     type1  type2  Rude  Figurative  Offensive  Dirty  \n",
       "0        1    NaN     1           0          0      0  \n",
       "1        1    4.0     1           1          1      0  \n",
       "2        1    NaN     0           0          0      0  \n",
       "3        1    NaN     1           0          0      0  \n",
       "4        1    NaN     1           0          1      0  \n",
       "..     ...    ...   ...         ...        ...    ...  \n",
       "457      1    NaN     1           0          0      0  \n",
       "458      1    NaN     1           0          0      0  \n",
       "459      1    NaN     1           0          0      0  \n",
       "460      1    NaN     1           0          0      0  \n",
       "461      1    NaN     1           0          0      0  \n",
       "\n",
       "[462 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Corpus = pd.read_excel('corpus.xlsx')\n",
    "Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
